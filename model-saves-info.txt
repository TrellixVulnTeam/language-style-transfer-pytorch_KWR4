
model_0.0005_50_12:05_03-16-2020 - discriminator only. dropout prob=0.5
model_0.0005_50_18:26_03-15-2020 - adv training after pretraining autoencoder (upto loss 0.2 and disc 80%)
model_0.0005_30_18:34_03-15-2020 - autoencoder training only - loss upto 0.1
model_0.0005_30_23:51_03-15-2020 - autoencoder only dropout prob = 0.2, upto loss 0.1
model_0.0005_30_09:50_03-16-2020 - disc. training only, dropout prob 0.2, accuracy > 80%

model_0.0005_50_01:00_03-17-2020 - adv training dropout prob=0.5, w/ pretrained models
model_0.0005_50_18:54_03-16-2020 - adv training dropout prob=0.2, w/ pretrained models
model_0.0005_50_01:57_03-17-2020 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64
model_0.0005_50_09:57_03-17-2020 - adv training dropout prob=0.5, w/ pretrained models (ae - 5 epochs)
model_0.0005_50_00:17_03-18-2020 - adv training dropout prob=0.2, w/o pretrained models, batchsize = 64

model_0.0005_1_10:42_03-18-2020 - autoencoder pretraining, one epoch only, dropout prob=0.2
model_0.0005_1_10:44_03-18-2020 - autoencoder pretraining, one epoch only, dropout prob=0.5
model_0.0005_50_11:35_03-18-2020 - autoencoder w/ pretraining, dropout prob=0.2, autencoder trained 1 epoch, discrminator trained for 1 epoch

model_0.0005_50_02:01_03-19-2020 - adv training w/o pretrained models, dropout_prob=0.5, batch_size=512
model_0.0005_50_02:04_03-19-2020 - adv training w/o pretrained models, dropout_prob=0.5, batch_size=256

model_0.0005_20_11:06_03-26-2020, model_0.0005_20_11:07_03-26-2020 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories
model_0.0005_20_11:05_03-26-2020 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64



model_0.0005_20_22:06_03-26-2020 - model_0.0005_20_11:06_03-26-2020's translated outputs 

model_0.0005_20_20:37_03-28-2020 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories

model_0.0005_20_Mar-28-2020_20-41-19, model_0.0005_20_Mar-28-2020_20-41-15 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64

model_0.0005_20_Mar-28-2020_21-02-10 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64
model_0.0005_20_Mar-29-2020_09-13-10 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories


model_0.0005_20_Apr-02-2020_11-42-24 - translated test outputs, using the 20 epochs model in model_0.0005_20_Mar-29-2020_09-13-10. 
                                        Used the textcnn models - textcnn-snapshot/2020-03-26_14-01-27/best_steps_29400.pt, textcnn-snapshot/2020-03-26_14-01-27/best_steps_6100.pt and textcnn-snapshot/2020-03-25_00-28-02/best_steps_25400.pt for predicting the sentiment of translated outputs. The accuracy with all these models is almost same. 




model_0.0005_20_Apr-07-2020_16-15-06 - 58k tweet pairs - 20 epochs
model_0.0005_50_Apr-07-2020_22-14-51 - 58k tweet pairs - 50 epochs

model_0.0005_50_Apr-08-2020_14-33-00 - 58k tweet pairs - 50 epochs - autoencoder LR = 0.001 and discriminator LR = 0.0005
model_0.0005_50_Apr-08-2020_17-26-10 - 58k tweet pairs - 50 epochs - autoencoder LR = 0.001 and discriminator LR = 0.0005


model_0.0005_70_Apr-09-2020_08-00-34 - autoencoder training only, with BPE
model_0.0005_70_Apr-09-2020_08-43-42 - discriminator training only, with BPE
model_0.0005_50_Apr-09-2020_15-23-19 - Adv training using pretrained models. 
                                        AE trained for 30 epochs (loss-0.5031),
                                         discriminator trained for 1 epoch (accuracy-0.937931321496956)

model_0.0005_50_Apr-12-2020_01-16-21 - Adv training using pretrained models. 
                                        AE trained for 30 epochs (loss-0.5031),
                                        discriminator trained for 1 epoch (accuracy-0.937931321496956),
                                        rho 0.5

model_0.0005_50_Apr-12-2020_01-20-17 - Adv training using pretrained models. 
                                        AE trained for 30 epochs (loss-0.5031),
                                        discriminator trained for 1 epoch (accuracy-0.937931321496956),
                                        rho 0.7


model_0.0005_20_Apr-09-2020_15-35-26 - Adv training w/o using pretrained models,
                                        200K random samples from 2.6M pairs

model_0.0005_20_Apr-09-2020_21-21-01 - Adv training w/o using pretrained models,
                                        200K random samples from 2.6M pairs
                                        rho = 0.5
model_0.0005_20_Apr-09-2020_23-21-53 - Adv training w/o using pretrained models,
                                        200K random samples from 2.6M pairs
                                        rho = 1       

model_0.0005_20_Apr-11-2020_11-05-30 - Adv training w/o using pretrained models,
                                        200K random samples from 2.6M pairs
                                        rho = 0.7

model_0.0005_5_Apr-11-2020_11-12-42 - Adv training w/o using pretrained models,
                                        200K random samples from 2.6M pairs
                                        rho = 1, pretrained from epoch 15