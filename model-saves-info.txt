
model_0.0005_50_12:05_03-16-2020 - discriminator only. dropout prob=0.5
model_0.0005_50_18:26_03-15-2020 - adv training after pretraining autoencoder (upto loss 0.2 and disc 80%)
model_0.0005_30_18:34_03-15-2020 - autoencoder training only - loss upto 0.1
model_0.0005_30_23:51_03-15-2020 - autoencoder only dropout prob = 0.2, upto loss 0.1
model_0.0005_30_09:50_03-16-2020 - disc. training only, dropout prob 0.2, accuracy > 80%

model_0.0005_50_01:00_03-17-2020 - adv training dropout prob=0.5, w/ pretrained models
model_0.0005_50_18:54_03-16-2020 - adv training dropout prob=0.2, w/ pretrained models
model_0.0005_50_01:57_03-17-2020 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64
model_0.0005_50_09:57_03-17-2020 - adv training dropout prob=0.5, w/ pretrained models (ae - 5 epochs)
model_0.0005_50_00:17_03-18-2020 - adv training dropout prob=0.2, w/o pretrained models, batchsize = 64

model_0.0005_1_10:42_03-18-2020 - autoencoder pretraining, one epoch only, dropout prob=0.2
model_0.0005_1_10:44_03-18-2020 - autoencoder pretraining, one epoch only, dropout prob=0.5
model_0.0005_50_11:35_03-18-2020 - autoencoder w/ pretraining, dropout prob=0.2, autencoder trained 1 epoch, discrminator trained for 1 epoch

model_0.0005_50_02:01_03-19-2020 - adv training w/o pretrained models, dropout_prob=0.5, batch_size=512
model_0.0005_50_02:04_03-19-2020 - adv training w/o pretrained models, dropout_prob=0.5, batch_size=256

model_0.0005_20_11:06_03-26-2020, model_0.0005_20_11:07_03-26-2020 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories
model_0.0005_20_11:05_03-26-2020 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64



model_0.0005_20_22:06_03-26-2020 - model_0.0005_20_11:06_03-26-2020's translated outputs 

model_0.0005_20_20:37_03-28-2020 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories

model_0.0005_20_Mar-28-2020_20-41-19, model_0.0005_20_Mar-28-2020_20-41-15 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64

model_0.0005_20_Mar-28-2020_21-02-10 - adv training dropout prob=0.5, w/o pretrained models, batchsize = 64
model_0.0005_20_Mar-29-2020_09-13-10 - adv training w/o pretrained models, dropout=0.5, batch_size=64, same number of positive and negative samples, 176787 samples in both categories


model_0.0005_20_Apr-02-2020_11-42-24 - translated test outputs, using the 20 epochs model in model_0.0005_20_Mar-29-2020_09-13-10. Used the textcnn models - textcnn-snapshot/2020-03-26_14-01-27/best_steps_29400.pt, textcnn-snapshot/2020-03-26_14-01-27/best_steps_6100.pt and textcnn-snapshot/2020-03-25_00-28-02/best_steps_25400.pt for predicting the sentiment of translated outputs. The accuracy with all these models is almost same. 
