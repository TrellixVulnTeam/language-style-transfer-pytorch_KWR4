------------------------------------------------
{   'batch_size': 64,
    'beam': 1,
    'dev': '../data/yelp/sentiment.dev',
    'dim_emb': 100,
    'dim_y': 200,
    'dim_z': 500,
    'dropout_keep_prob': 0.5,
    'embedding': '',
    'filter_sizes': '1,2,3,4,5',
    'gamma_decay': 1,
    'gamma_init': 0.1,
    'gamma_min': 0.1,
    'learning_rate': 0.0005,
    'load_model': False,
    'log_dir': '../logs',
    'max_epochs': 500,
    'max_seq_length': 20,
    'max_train_size': -1,
    'model': '../tmp/model',
    'n_filters': 128,
    'n_layers': 1,
    'online_testing': False,
    'output': '../tmp/sentiment.dev',
    'rho': 1,
    'steps_per_checkpoint': 1000,
    'test': '',
    'train': '../data/yelp/sentimentshort.train',
    'vocab': '../tmp/yelp.vocab'}
------------------------------------------------
#sents of training file 0: 300
#sents of training file 1: 300
vocab size:  180
Epoch:  0
Avg Loss:  tensor(233.0695, grad_fn=<AddBackward0>)
---------

Epoch:  1
Avg Loss:  tensor(199.6116, grad_fn=<AddBackward0>)
---------

Epoch:  2
Avg Loss:  tensor(198.3476, grad_fn=<AddBackward0>)
---------

Epoch:  3
Avg Loss:  tensor(193.1628, grad_fn=<AddBackward0>)
---------

Epoch:  4
Avg Loss:  tensor(186.5333, grad_fn=<AddBackward0>)
---------

Epoch:  5
Avg Loss:  tensor(182.5158, grad_fn=<AddBackward0>)
---------

Epoch:  6
Avg Loss:  tensor(182.0620, grad_fn=<AddBackward0>)
---------

Epoch:  7
Avg Loss:  tensor(181.0752, grad_fn=<AddBackward0>)
---------

Epoch:  8
Avg Loss:  tensor(180.0941, grad_fn=<AddBackward0>)
---------

Epoch:  9
Avg Loss:  tensor(179.8301, grad_fn=<AddBackward0>)
---------

Epoch:  10
Avg Loss:  tensor(180.3079, grad_fn=<AddBackward0>)
---------

Epoch:  11
Avg Loss:  tensor(179.0682, grad_fn=<AddBackward0>)
---------

Epoch:  12
Avg Loss:  tensor(179.3028, grad_fn=<AddBackward0>)
---------

Epoch:  13
Avg Loss:  tensor(179.7130, grad_fn=<AddBackward0>)
---------

Epoch:  14
Avg Loss:  tensor(178.1187, grad_fn=<AddBackward0>)
---------

Epoch:  15
Avg Loss:  tensor(179.3479, grad_fn=<AddBackward0>)
---------

Epoch:  16
Avg Loss:  tensor(179.3821, grad_fn=<AddBackward0>)
---------

Epoch:  17
Avg Loss:  tensor(178.4245, grad_fn=<AddBackward0>)
---------

Epoch:  18
Avg Loss:  tensor(178.6278, grad_fn=<AddBackward0>)
---------

Epoch:  19
Avg Loss:  tensor(177.8984, grad_fn=<AddBackward0>)
---------

Epoch:  20
Avg Loss:  tensor(177.1214, grad_fn=<AddBackward0>)
---------

Epoch:  21
Avg Loss:  tensor(176.0807, grad_fn=<AddBackward0>)
---------

Epoch:  22
Avg Loss:  tensor(176.7290, grad_fn=<AddBackward0>)
---------

Epoch:  23
Avg Loss:  tensor(177.0819, grad_fn=<AddBackward0>)
---------

Epoch:  24
Avg Loss:  tensor(175.5222, grad_fn=<AddBackward0>)
---------

Epoch:  25
Avg Loss:  tensor(177.6198, grad_fn=<AddBackward0>)
---------

Epoch:  26
Avg Loss:  tensor(176.4165, grad_fn=<AddBackward0>)
---------

Epoch:  27
Avg Loss:  tensor(175.7878, grad_fn=<AddBackward0>)
---------

Epoch:  28
Avg Loss:  tensor(175.7624, grad_fn=<AddBackward0>)
---------

Epoch:  29
Avg Loss:  tensor(177.8533, grad_fn=<AddBackward0>)
---------

Epoch:  30
Avg Loss:  tensor(174.9679, grad_fn=<AddBackward0>)
---------

Epoch:  31
Avg Loss:  tensor(174.8917, grad_fn=<AddBackward0>)
---------

Epoch:  32
Avg Loss:  tensor(173.9483, grad_fn=<AddBackward0>)
---------

Epoch:  33
Avg Loss:  tensor(173.6869, grad_fn=<AddBackward0>)
---------

Epoch:  34
Avg Loss:  tensor(174.0947, grad_fn=<AddBackward0>)
---------

Epoch:  35
Avg Loss:  tensor(173.8189, grad_fn=<AddBackward0>)
---------

Epoch:  36
Avg Loss:  tensor(173.7699, grad_fn=<AddBackward0>)
---------

Epoch:  37
Avg Loss:  tensor(172.8842, grad_fn=<AddBackward0>)
---------

Epoch:  38
Avg Loss:  tensor(173.6721, grad_fn=<AddBackward0>)
---------

Epoch:  39
Avg Loss:  tensor(173.1219, grad_fn=<AddBackward0>)
---------

Epoch:  40
Avg Loss:  tensor(172.8118, grad_fn=<AddBackward0>)
---------

Epoch:  41
Avg Loss:  tensor(173.1761, grad_fn=<AddBackward0>)
---------

Epoch:  42
Avg Loss:  tensor(172.2644, grad_fn=<AddBackward0>)
---------

Epoch:  43
Avg Loss:  tensor(171.7504, grad_fn=<AddBackward0>)
---------

Epoch:  44
Avg Loss:  tensor(171.7637, grad_fn=<AddBackward0>)
---------

Epoch:  45
Avg Loss:  tensor(171.3978, grad_fn=<AddBackward0>)
---------

Epoch:  46
Avg Loss:  tensor(170.7446, grad_fn=<AddBackward0>)
---------

Epoch:  47
Avg Loss:  tensor(171.6432, grad_fn=<AddBackward0>)
---------

Epoch:  48
Avg Loss:  tensor(170.9795, grad_fn=<AddBackward0>)
---------

Epoch:  49
Avg Loss:  tensor(169.9532, grad_fn=<AddBackward0>)
---------

Epoch:  50
Avg Loss:  tensor(170.7684, grad_fn=<AddBackward0>)
---------

Epoch:  51
Avg Loss:  tensor(170.0294, grad_fn=<AddBackward0>)
---------

Epoch:  52
Avg Loss:  tensor(169.2909, grad_fn=<AddBackward0>)
---------

Epoch:  53
Avg Loss:  tensor(169.3050, grad_fn=<AddBackward0>)
---------

Epoch:  54
Avg Loss:  tensor(169.1344, grad_fn=<AddBackward0>)
---------

Epoch:  55
Avg Loss:  tensor(169.1425, grad_fn=<AddBackward0>)
---------

Epoch:  56
Avg Loss:  tensor(169.3498, grad_fn=<AddBackward0>)
---------

Epoch:  57
Avg Loss:  tensor(168.3463, grad_fn=<AddBackward0>)
---------

Epoch:  58
Avg Loss:  tensor(168.0411, grad_fn=<AddBackward0>)
---------

Epoch:  59
Avg Loss:  tensor(168.4590, grad_fn=<AddBackward0>)
---------

Epoch:  60
Avg Loss:  tensor(168.5751, grad_fn=<AddBackward0>)
---------

Epoch:  61
Avg Loss:  tensor(166.9795, grad_fn=<AddBackward0>)
---------

Epoch:  62
Avg Loss:  tensor(167.4303, grad_fn=<AddBackward0>)
---------

Epoch:  63
Avg Loss:  tensor(167.5316, grad_fn=<AddBackward0>)
---------

Epoch:  64
Avg Loss:  tensor(167.0775, grad_fn=<AddBackward0>)
---------

Epoch:  65
Avg Loss:  tensor(166.6881, grad_fn=<AddBackward0>)
---------

Epoch:  66
Avg Loss:  tensor(166.5026, grad_fn=<AddBackward0>)
---------

Epoch:  67
Avg Loss:  tensor(166.4228, grad_fn=<AddBackward0>)
---------

Epoch:  68
Avg Loss:  tensor(166.8342, grad_fn=<AddBackward0>)
---------

Epoch:  69
Avg Loss:  tensor(164.6226, grad_fn=<AddBackward0>)
---------

Epoch:  70
Avg Loss:  tensor(165.7737, grad_fn=<AddBackward0>)
---------

Epoch:  71
Avg Loss:  tensor(165.7470, grad_fn=<AddBackward0>)
---------

Epoch:  72
Avg Loss:  tensor(164.7194, grad_fn=<AddBackward0>)
---------

Epoch:  73
Avg Loss:  tensor(165.8479, grad_fn=<AddBackward0>)
---------

Epoch:  74
Avg Loss:  tensor(165.4705, grad_fn=<AddBackward0>)
---------

Epoch:  75
Avg Loss:  tensor(164.9409, grad_fn=<AddBackward0>)
---------

Epoch:  76
Avg Loss:  tensor(165.7040, grad_fn=<AddBackward0>)
---------

Epoch:  77
Avg Loss:  tensor(163.9042, grad_fn=<AddBackward0>)
---------

Epoch:  78
Avg Loss:  tensor(164.6752, grad_fn=<AddBackward0>)
---------

Epoch:  79
Avg Loss:  tensor(164.3226, grad_fn=<AddBackward0>)
---------

Epoch:  80
Avg Loss:  tensor(163.5709, grad_fn=<AddBackward0>)
---------

Epoch:  81
Avg Loss:  tensor(163.2638, grad_fn=<AddBackward0>)
---------

Epoch:  82
Avg Loss:  tensor(163.7973, grad_fn=<AddBackward0>)
---------

Epoch:  83
Avg Loss:  tensor(163.1423, grad_fn=<AddBackward0>)
---------

Epoch:  84
Avg Loss:  tensor(162.9140, grad_fn=<AddBackward0>)
---------

Epoch:  85
Avg Loss:  tensor(163.4122, grad_fn=<AddBackward0>)
---------

Epoch:  86
Avg Loss:  tensor(162.5358, grad_fn=<AddBackward0>)
---------

Epoch:  87
Avg Loss:  tensor(163.1127, grad_fn=<AddBackward0>)
---------

Epoch:  88
Avg Loss:  tensor(163.1752, grad_fn=<AddBackward0>)
---------

Epoch:  89
Avg Loss:  tensor(161.8886, grad_fn=<AddBackward0>)
---------

Epoch:  90
Avg Loss:  tensor(162.5371, grad_fn=<AddBackward0>)
---------

Epoch:  91
Avg Loss:  tensor(162.4371, grad_fn=<AddBackward0>)
---------

Epoch:  92
Avg Loss:  tensor(162.6276, grad_fn=<AddBackward0>)
---------

Epoch:  93
Avg Loss:  tensor(162.2255, grad_fn=<AddBackward0>)
---------

Epoch:  94
Avg Loss:  tensor(161.6770, grad_fn=<AddBackward0>)
---------

Epoch:  95
Avg Loss:  tensor(162.1073, grad_fn=<AddBackward0>)
---------

Epoch:  96
Avg Loss:  tensor(161.9841, grad_fn=<AddBackward0>)
---------

Epoch:  97
Avg Loss:  tensor(159.9319, grad_fn=<AddBackward0>)
---------

Epoch:  98
Avg Loss:  tensor(159.3772, grad_fn=<AddBackward0>)
---------

Epoch:  99
Avg Loss:  tensor(160.6299, grad_fn=<AddBackward0>)
---------

Epoch:  100
Avg Loss:  tensor(160.7540, grad_fn=<AddBackward0>)
---------

Epoch:  101
Avg Loss:  tensor(160.9435, grad_fn=<AddBackward0>)
---------

Epoch:  102
Avg Loss:  tensor(159.5620, grad_fn=<AddBackward0>)
---------

Epoch:  103
Avg Loss:  tensor(159.7111, grad_fn=<AddBackward0>)
---------

Epoch:  104
Avg Loss:  tensor(158.9800, grad_fn=<AddBackward0>)
---------

Epoch:  105
Avg Loss:  tensor(158.6812, grad_fn=<AddBackward0>)
---------

Epoch:  106
Avg Loss:  tensor(159.1776, grad_fn=<AddBackward0>)
---------

Epoch:  107
Avg Loss:  tensor(158.4878, grad_fn=<AddBackward0>)
---------

Epoch:  108
Avg Loss:  tensor(158.2481, grad_fn=<AddBackward0>)
---------

Epoch:  109
Avg Loss:  tensor(159.6367, grad_fn=<AddBackward0>)
---------

Epoch:  110
Avg Loss:  tensor(157.8640, grad_fn=<AddBackward0>)
---------

Epoch:  111
Avg Loss:  tensor(158.7513, grad_fn=<AddBackward0>)
---------

Epoch:  112
Avg Loss:  tensor(158.9313, grad_fn=<AddBackward0>)
---------

Epoch:  113
Avg Loss:  tensor(157.8062, grad_fn=<AddBackward0>)
---------

Epoch:  114
Avg Loss:  tensor(158.5257, grad_fn=<AddBackward0>)
---------

Epoch:  115
Avg Loss:  tensor(157.8139, grad_fn=<AddBackward0>)
---------

Epoch:  116
Avg Loss:  tensor(156.9360, grad_fn=<AddBackward0>)
---------

Epoch:  117
Avg Loss:  tensor(157.7296, grad_fn=<AddBackward0>)
---------

Epoch:  118
Avg Loss:  tensor(156.9866, grad_fn=<AddBackward0>)
---------

Epoch:  119
Avg Loss:  tensor(158.1723, grad_fn=<AddBackward0>)
---------

Epoch:  120
Avg Loss:  tensor(157.1001, grad_fn=<AddBackward0>)
---------

Epoch:  121
Avg Loss:  tensor(156.0439, grad_fn=<AddBackward0>)
---------

Epoch:  122
Avg Loss:  tensor(156.8345, grad_fn=<AddBackward0>)
---------

Epoch:  123
Avg Loss:  tensor(156.9209, grad_fn=<AddBackward0>)
---------

Epoch:  124
Avg Loss:  tensor(156.0305, grad_fn=<AddBackward0>)
---------

Epoch:  125
Avg Loss:  tensor(156.9740, grad_fn=<AddBackward0>)
---------

Epoch:  126
Avg Loss:  tensor(157.0684, grad_fn=<AddBackward0>)
---------

Epoch:  127
Avg Loss:  tensor(155.5947, grad_fn=<AddBackward0>)
---------

Epoch:  128
Avg Loss:  tensor(154.1942, grad_fn=<AddBackward0>)
---------

Epoch:  129
Avg Loss:  tensor(155.9468, grad_fn=<AddBackward0>)
---------

Epoch:  130
Avg Loss:  tensor(156.0100, grad_fn=<AddBackward0>)
---------

Epoch:  131
Avg Loss:  tensor(155.9845, grad_fn=<AddBackward0>)
---------

Epoch:  132
Avg Loss:  tensor(157.0074, grad_fn=<AddBackward0>)
---------

Epoch:  133
Avg Loss:  tensor(154.5227, grad_fn=<AddBackward0>)
---------

Epoch:  134
Avg Loss:  tensor(156.1048, grad_fn=<AddBackward0>)
---------

Epoch:  135
Avg Loss:  tensor(155.4177, grad_fn=<AddBackward0>)
---------

Epoch:  136
Avg Loss:  tensor(155.7099, grad_fn=<AddBackward0>)
---------

Epoch:  137
Avg Loss:  tensor(154.0112, grad_fn=<AddBackward0>)
---------

Epoch:  138
Avg Loss:  tensor(155.4336, grad_fn=<AddBackward0>)
---------

Epoch:  139
Avg Loss:  tensor(154.5589, grad_fn=<AddBackward0>)
---------

Epoch:  140
Avg Loss:  tensor(155.3420, grad_fn=<AddBackward0>)
---------

Epoch:  141
Avg Loss:  tensor(154.9921, grad_fn=<AddBackward0>)
---------

Epoch:  142
Avg Loss:  tensor(155.0374, grad_fn=<AddBackward0>)
---------

Epoch:  143
Avg Loss:  tensor(153.4189, grad_fn=<AddBackward0>)
---------

Epoch:  144
Avg Loss:  tensor(153.0647, grad_fn=<AddBackward0>)
---------

Epoch:  145
Avg Loss:  tensor(153.9698, grad_fn=<AddBackward0>)
---------

Epoch:  146
Avg Loss:  tensor(153.9353, grad_fn=<AddBackward0>)
---------

Epoch:  147
Avg Loss:  tensor(153.7576, grad_fn=<AddBackward0>)
---------

Epoch:  148
Avg Loss:  tensor(152.9382, grad_fn=<AddBackward0>)
---------

Epoch:  149
Avg Loss:  tensor(153.8253, grad_fn=<AddBackward0>)
---------

Epoch:  150
Avg Loss:  tensor(152.5733, grad_fn=<AddBackward0>)
---------

Epoch:  151
Avg Loss:  tensor(153.9323, grad_fn=<AddBackward0>)
---------

Epoch:  152
Avg Loss:  tensor(153.6487, grad_fn=<AddBackward0>)
---------

Epoch:  153
Avg Loss:  tensor(152.7224, grad_fn=<AddBackward0>)
---------

Epoch:  154
Avg Loss:  tensor(152.9664, grad_fn=<AddBackward0>)
---------

Epoch:  155
Avg Loss:  tensor(153.7633, grad_fn=<AddBackward0>)
---------

Epoch:  156
Avg Loss:  tensor(152.7406, grad_fn=<AddBackward0>)
---------

Epoch:  157
Avg Loss:  tensor(153.6536, grad_fn=<AddBackward0>)
---------

Epoch:  158
Avg Loss:  tensor(151.3938, grad_fn=<AddBackward0>)
---------

Epoch:  159
Avg Loss:  tensor(153.5475, grad_fn=<AddBackward0>)
---------

Epoch:  160
Avg Loss:  tensor(151.7439, grad_fn=<AddBackward0>)
---------

Epoch:  161
Avg Loss:  tensor(151.1738, grad_fn=<AddBackward0>)
---------

Epoch:  162
Avg Loss:  tensor(152.1885, grad_fn=<AddBackward0>)
---------

Epoch:  163
Avg Loss:  tensor(151.8273, grad_fn=<AddBackward0>)
---------

Epoch:  164
Avg Loss:  tensor(153.9514, grad_fn=<AddBackward0>)
---------

Epoch:  165
Avg Loss:  tensor(152.4671, grad_fn=<AddBackward0>)
---------

Epoch:  166
Avg Loss:  tensor(151.6759, grad_fn=<AddBackward0>)
---------

Epoch:  167
Avg Loss:  tensor(152.5656, grad_fn=<AddBackward0>)
---------

Epoch:  168
Avg Loss:  tensor(150.7250, grad_fn=<AddBackward0>)
---------

Epoch:  169
Avg Loss:  tensor(150.7510, grad_fn=<AddBackward0>)
---------

Epoch:  170
Avg Loss:  tensor(151.5746, grad_fn=<AddBackward0>)
---------

Epoch:  171
Avg Loss:  tensor(151.9406, grad_fn=<AddBackward0>)
---------

Epoch:  172
Avg Loss:  tensor(149.2818, grad_fn=<AddBackward0>)
---------

Epoch:  173
Avg Loss:  tensor(151.5332, grad_fn=<AddBackward0>)
---------

Epoch:  174
Avg Loss:  tensor(151.0598, grad_fn=<AddBackward0>)
---------

Epoch:  175
Avg Loss:  tensor(151.2162, grad_fn=<AddBackward0>)
---------

Epoch:  176
Avg Loss:  tensor(150.8032, grad_fn=<AddBackward0>)
---------

Epoch:  177
Avg Loss:  tensor(151.1721, grad_fn=<AddBackward0>)
---------

Epoch:  178
Avg Loss:  tensor(151.1414, grad_fn=<AddBackward0>)
---------

Epoch:  179
Avg Loss:  tensor(149.4600, grad_fn=<AddBackward0>)
---------

Epoch:  180
Avg Loss:  tensor(151.9108, grad_fn=<AddBackward0>)
---------

Epoch:  181
Avg Loss:  tensor(151.3078, grad_fn=<AddBackward0>)
---------

Epoch:  182
Avg Loss:  tensor(150.5091, grad_fn=<AddBackward0>)
---------

Epoch:  183
Avg Loss:  tensor(149.0759, grad_fn=<AddBackward0>)
---------

Epoch:  184
Avg Loss:  tensor(150.1150, grad_fn=<AddBackward0>)
---------

Epoch:  185
Avg Loss:  tensor(150.6400, grad_fn=<AddBackward0>)
---------

Epoch:  186
Avg Loss:  tensor(149.0337, grad_fn=<AddBackward0>)
---------

Epoch:  187
Avg Loss:  tensor(149.4945, grad_fn=<AddBackward0>)
---------

Epoch:  188
Avg Loss:  tensor(150.7668, grad_fn=<AddBackward0>)
---------

Epoch:  189
Avg Loss:  tensor(148.2247, grad_fn=<AddBackward0>)
---------

Epoch:  190
Avg Loss:  tensor(149.4295, grad_fn=<AddBackward0>)
---------

Epoch:  191
Avg Loss:  tensor(148.1428, grad_fn=<AddBackward0>)
---------

Epoch:  192
Avg Loss:  tensor(148.7606, grad_fn=<AddBackward0>)
---------

Epoch:  193
Avg Loss:  tensor(150.3747, grad_fn=<AddBackward0>)
---------

Epoch:  194
Avg Loss:  tensor(148.7418, grad_fn=<AddBackward0>)
---------

Epoch:  195
Avg Loss:  tensor(150.3794, grad_fn=<AddBackward0>)
---------

Epoch:  196
Avg Loss:  tensor(148.3143, grad_fn=<AddBackward0>)
---------

Epoch:  197
Avg Loss:  tensor(149.3677, grad_fn=<AddBackward0>)
---------

Epoch:  198
Avg Loss:  tensor(150.4194, grad_fn=<AddBackward0>)
---------

Epoch:  199
Avg Loss:  tensor(148.8770, grad_fn=<AddBackward0>)
---------

Epoch:  200
Avg Loss:  tensor(148.2674, grad_fn=<AddBackward0>)
---------

Epoch:  201
Avg Loss:  tensor(148.8642, grad_fn=<AddBackward0>)
---------

Epoch:  202
Avg Loss:  tensor(148.5502, grad_fn=<AddBackward0>)
---------

Epoch:  203
Avg Loss:  tensor(149.1925, grad_fn=<AddBackward0>)
---------

Epoch:  204
Avg Loss:  tensor(148.0387, grad_fn=<AddBackward0>)
---------

Epoch:  205
Avg Loss:  tensor(147.9086, grad_fn=<AddBackward0>)
---------

Epoch:  206
Avg Loss:  tensor(149.0647, grad_fn=<AddBackward0>)
---------

Epoch:  207
Avg Loss:  tensor(148.0156, grad_fn=<AddBackward0>)
---------

Epoch:  208
Avg Loss:  tensor(148.8622, grad_fn=<AddBackward0>)
---------

Epoch:  209
Avg Loss:  tensor(148.5026, grad_fn=<AddBackward0>)
---------

Epoch:  210
Avg Loss:  tensor(146.5168, grad_fn=<AddBackward0>)
---------

Epoch:  211
Avg Loss:  tensor(150.0152, grad_fn=<AddBackward0>)
---------

Epoch:  212
Avg Loss:  tensor(147.2598, grad_fn=<AddBackward0>)
---------

Epoch:  213
Avg Loss:  tensor(148.2408, grad_fn=<AddBackward0>)
---------

Epoch:  214
Avg Loss:  tensor(148.2866, grad_fn=<AddBackward0>)
---------

Epoch:  215
Avg Loss:  tensor(147.4017, grad_fn=<AddBackward0>)
---------

Epoch:  216
Avg Loss:  tensor(146.2906, grad_fn=<AddBackward0>)
---------

Epoch:  217
Avg Loss:  tensor(146.9291, grad_fn=<AddBackward0>)
---------

Epoch:  218
Avg Loss:  tensor(148.8286, grad_fn=<AddBackward0>)
---------

Epoch:  219
Avg Loss:  tensor(148.0324, grad_fn=<AddBackward0>)
---------

Epoch:  220
Avg Loss:  tensor(148.0894, grad_fn=<AddBackward0>)
---------

Epoch:  221
Avg Loss:  tensor(148.9061, grad_fn=<AddBackward0>)
---------

Epoch:  222
Avg Loss:  tensor(146.4442, grad_fn=<AddBackward0>)
---------

Epoch:  223
Avg Loss:  tensor(147.3180, grad_fn=<AddBackward0>)
---------

Epoch:  224
Avg Loss:  tensor(146.7579, grad_fn=<AddBackward0>)
---------

Epoch:  225
Avg Loss:  tensor(147.3624, grad_fn=<AddBackward0>)
---------

Epoch:  226
Avg Loss:  tensor(146.2463, grad_fn=<AddBackward0>)
---------

Epoch:  227
Avg Loss:  tensor(147.7840, grad_fn=<AddBackward0>)
---------

Epoch:  228
Avg Loss:  tensor(147.5302, grad_fn=<AddBackward0>)
---------

Epoch:  229
Avg Loss:  tensor(147.6624, grad_fn=<AddBackward0>)
---------

Epoch:  230
Avg Loss:  tensor(145.1352, grad_fn=<AddBackward0>)
---------

Epoch:  231
Avg Loss:  tensor(147.1433, grad_fn=<AddBackward0>)
---------

Epoch:  232
Avg Loss:  tensor(147.0893, grad_fn=<AddBackward0>)
---------

Epoch:  233
Avg Loss:  tensor(147.0094, grad_fn=<AddBackward0>)
---------

Epoch:  234
Avg Loss:  tensor(146.8008, grad_fn=<AddBackward0>)
---------

Epoch:  235
Avg Loss:  tensor(146.1614, grad_fn=<AddBackward0>)
---------

Epoch:  236
Avg Loss:  tensor(146.6943, grad_fn=<AddBackward0>)
---------

Epoch:  237
Avg Loss:  tensor(148.2946, grad_fn=<AddBackward0>)
---------

Epoch:  238
Avg Loss:  tensor(145.5512, grad_fn=<AddBackward0>)
---------

Epoch:  239
Avg Loss:  tensor(146.6275, grad_fn=<AddBackward0>)
---------

Epoch:  240
Avg Loss:  tensor(145.7545, grad_fn=<AddBackward0>)
---------

Epoch:  241
Avg Loss:  tensor(147.3624, grad_fn=<AddBackward0>)
---------

Epoch:  242
Avg Loss:  tensor(148.8140, grad_fn=<AddBackward0>)
---------

Epoch:  243
Avg Loss:  tensor(147.4033, grad_fn=<AddBackward0>)
---------

Epoch:  244
Avg Loss:  tensor(145.2724, grad_fn=<AddBackward0>)
---------

Epoch:  245
Avg Loss:  tensor(147.6529, grad_fn=<AddBackward0>)
---------

Epoch:  246
Avg Loss:  tensor(145.9863, grad_fn=<AddBackward0>)
---------

Epoch:  247
Avg Loss:  tensor(146.4911, grad_fn=<AddBackward0>)
---------

Epoch:  248
Avg Loss:  tensor(144.6310, grad_fn=<AddBackward0>)
---------

Epoch:  249
Avg Loss:  tensor(145.1365, grad_fn=<AddBackward0>)
---------

Epoch:  250
Avg Loss:  tensor(144.6292, grad_fn=<AddBackward0>)
---------

Epoch:  251
Avg Loss:  tensor(146.5974, grad_fn=<AddBackward0>)
---------

Epoch:  252
Avg Loss:  tensor(146.6381, grad_fn=<AddBackward0>)
---------

Epoch:  253
Avg Loss:  tensor(145.7781, grad_fn=<AddBackward0>)
---------

Epoch:  254
Avg Loss:  tensor(147.2897, grad_fn=<AddBackward0>)
---------

Epoch:  255
Avg Loss:  tensor(145.7469, grad_fn=<AddBackward0>)
---------

Epoch:  256
Avg Loss:  tensor(145.1008, grad_fn=<AddBackward0>)
---------

Epoch:  257
Avg Loss:  tensor(145.0535, grad_fn=<AddBackward0>)
---------

Epoch:  258
Avg Loss:  tensor(144.0526, grad_fn=<AddBackward0>)
---------

Epoch:  259
Avg Loss:  tensor(145.2109, grad_fn=<AddBackward0>)
---------

Epoch:  260
Avg Loss:  tensor(145.3628, grad_fn=<AddBackward0>)
---------

Epoch:  261
Avg Loss:  tensor(144.5823, grad_fn=<AddBackward0>)
---------

Epoch:  262
Avg Loss:  tensor(144.2933, grad_fn=<AddBackward0>)
---------

Epoch:  263
Avg Loss:  tensor(144.9538, grad_fn=<AddBackward0>)
---------

Epoch:  264
Avg Loss:  tensor(143.8781, grad_fn=<AddBackward0>)
---------

Epoch:  265
Avg Loss:  tensor(146.5791, grad_fn=<AddBackward0>)
---------

Epoch:  266
Avg Loss:  tensor(144.6226, grad_fn=<AddBackward0>)
---------

Epoch:  267
Avg Loss:  tensor(145.1825, grad_fn=<AddBackward0>)
---------

Epoch:  268
Avg Loss:  tensor(145.6528, grad_fn=<AddBackward0>)
---------

Epoch:  269
Avg Loss:  tensor(144.3646, grad_fn=<AddBackward0>)
---------

Epoch:  270
Avg Loss:  tensor(145.3691, grad_fn=<AddBackward0>)
---------

Epoch:  271
Avg Loss:  tensor(145.0833, grad_fn=<AddBackward0>)
---------

Epoch:  272
Avg Loss:  tensor(145.4627, grad_fn=<AddBackward0>)
---------

Epoch:  273
Avg Loss:  tensor(144.1937, grad_fn=<AddBackward0>)
---------

Epoch:  274
Avg Loss:  tensor(144.8909, grad_fn=<AddBackward0>)
---------

Epoch:  275
Avg Loss:  tensor(145.7432, grad_fn=<AddBackward0>)
---------

Epoch:  276
Avg Loss:  tensor(143.7243, grad_fn=<AddBackward0>)
---------

Epoch:  277
Avg Loss:  tensor(144.2193, grad_fn=<AddBackward0>)
---------

Epoch:  278
Avg Loss:  tensor(144.5163, grad_fn=<AddBackward0>)
---------

Epoch:  279
Avg Loss:  tensor(142.9764, grad_fn=<AddBackward0>)
---------

Epoch:  280
Avg Loss:  tensor(145.5522, grad_fn=<AddBackward0>)
---------

Epoch:  281
Avg Loss:  tensor(144.1531, grad_fn=<AddBackward0>)
---------

Epoch:  282
Avg Loss:  tensor(145.2180, grad_fn=<AddBackward0>)
---------

Epoch:  283
Avg Loss:  tensor(144.3499, grad_fn=<AddBackward0>)
---------

Epoch:  284
Avg Loss:  tensor(143.1116, grad_fn=<AddBackward0>)
---------

Epoch:  285
Avg Loss:  tensor(142.8236, grad_fn=<AddBackward0>)
---------

Epoch:  286
Avg Loss:  tensor(144.5842, grad_fn=<AddBackward0>)
---------

Epoch:  287
Avg Loss:  tensor(143.3003, grad_fn=<AddBackward0>)
---------

Epoch:  288
Avg Loss:  tensor(143.9590, grad_fn=<AddBackward0>)
---------

Epoch:  289
Avg Loss:  tensor(143.6377, grad_fn=<AddBackward0>)
---------

Epoch:  290
Avg Loss:  tensor(145.9726, grad_fn=<AddBackward0>)
---------

Epoch:  291
Avg Loss:  tensor(144.6042, grad_fn=<AddBackward0>)
---------

Epoch:  292
Avg Loss:  tensor(143.3482, grad_fn=<AddBackward0>)
---------

Epoch:  293
Avg Loss:  tensor(145.9762, grad_fn=<AddBackward0>)
---------

Epoch:  294
Avg Loss:  tensor(143.5338, grad_fn=<AddBackward0>)
---------

Epoch:  295
Avg Loss:  tensor(142.5961, grad_fn=<AddBackward0>)
---------

Epoch:  296
Avg Loss:  tensor(143.5554, grad_fn=<AddBackward0>)
---------

Epoch:  297
Avg Loss:  tensor(143.5631, grad_fn=<AddBackward0>)
---------

Epoch:  298
Avg Loss:  tensor(143.9391, grad_fn=<AddBackward0>)
---------

Epoch:  299
Avg Loss:  tensor(144.4161, grad_fn=<AddBackward0>)
---------

Epoch:  300
Avg Loss:  tensor(142.8466, grad_fn=<AddBackward0>)
---------

Epoch:  301
Avg Loss:  tensor(143.0494, grad_fn=<AddBackward0>)
---------

Epoch:  302
Avg Loss:  tensor(144.8134, grad_fn=<AddBackward0>)
---------

Epoch:  303
Avg Loss:  tensor(143.3461, grad_fn=<AddBackward0>)
---------

Epoch:  304
Avg Loss:  tensor(143.0632, grad_fn=<AddBackward0>)
---------

Epoch:  305
Avg Loss:  tensor(143.5840, grad_fn=<AddBackward0>)
---------

Epoch:  306
Avg Loss:  tensor(142.6354, grad_fn=<AddBackward0>)
---------

Epoch:  307
Avg Loss:  tensor(142.7957, grad_fn=<AddBackward0>)
---------

Epoch:  308
Avg Loss:  tensor(144.0252, grad_fn=<AddBackward0>)
---------

Epoch:  309
Avg Loss:  tensor(141.9131, grad_fn=<AddBackward0>)
---------

Epoch:  310
Avg Loss:  tensor(145.1169, grad_fn=<AddBackward0>)
---------

Epoch:  311
Avg Loss:  tensor(144.7946, grad_fn=<AddBackward0>)
---------

Epoch:  312
Avg Loss:  tensor(143.3187, grad_fn=<AddBackward0>)
---------

Epoch:  313
Avg Loss:  tensor(142.9744, grad_fn=<AddBackward0>)
---------

Epoch:  314
Avg Loss:  tensor(142.1608, grad_fn=<AddBackward0>)
---------

Epoch:  315
Avg Loss:  tensor(142.2348, grad_fn=<AddBackward0>)
---------

Epoch:  316
Avg Loss:  tensor(142.7997, grad_fn=<AddBackward0>)
---------

Epoch:  317
Avg Loss:  tensor(141.9765, grad_fn=<AddBackward0>)------------------------------------------------
{   'batch_size': 64,
    'beam': 1,
    'dev': '../data/yelp/sentiment.dev',
    'dim_emb': 100,
    'dim_y': 200,
    'dim_z': 500,
    'dropout_keep_prob': 0.5,
    'embedding': '',
    'filter_sizes': '1,2,3,4,5',
    'gamma_decay': 1,
    'gamma_init': 0.1,
    'gamma_min': 0.1,
    'learning_rate': 0.0005,
    'load_model': False,
    'log_dir': '../logs',
    'max_epochs': 500,
    'max_seq_length': 20,
    'max_train_size': -1,
    'model': '../tmp/model',
    'n_filters': 128,
    'n_layers': 1,
    'online_testing': False,
    'output': '../tmp/sentiment.dev',
    'rho': 1,
    'steps_per_checkpoint': 1000,
    'test': '',
    'train': '../data/yelp/sentimentshort.train',
    'vocab': '../tmp/yelp.vocab'}
------------------------------------------------
#sents of training file 0: 300
#sents of training file 1: 300
vocab size:  180
Epoch:  0
Avg Loss:  tensor(2964.3367, grad_fn=<AddBackward0>)
---------

Epoch:  1
Avg Loss:  tensor(1468.5710, grad_fn=<AddBackward0>)
---------

Epoch:  2
Avg Loss:  tensor(1016.6053, grad_fn=<AddBackward0>)
---------

Epoch:  3
Avg Loss:  tensor(1089.9688, grad_fn=<AddBackward0>)
---------

Epoch:  4
Avg Loss:  tensor(673.3275, grad_fn=<AddBackward0>)
---------

Epoch:  5
Avg Loss:  tensor(687.2099, grad_fn=<AddBackward0>)
---------

Epoch:  6
Avg Loss:  tensor(929.1498, grad_fn=<AddBackward0>)
---------

Epoch:  7
Avg Loss:  tensor(938.8843, grad_fn=<AddBackward0>)
---------

Epoch:  8
Avg Loss:  tensor(730.9116, grad_fn=<AddBackward0>)
---------

Epoch:  9
Avg Loss:  tensor(567.6790, grad_fn=<AddBackward0>)
---------

Epoch:  10
Avg Loss:  tensor(621.1799, grad_fn=<AddBackward0>)
---------

Epoch:  11
Avg Loss:  tensor(645.3057, grad_fn=<AddBackward0>)
---------

Epoch:  12
Avg Loss:  tensor(683.6171, grad_fn=<AddBackward0>)
---------

Epoch:  13
Avg Loss:  tensor(929.3063, grad_fn=<AddBackward0>)
---------

Epoch:  14
Avg Loss:  tensor(527.6966, grad_fn=<AddBackward0>)
---------

Epoch:  15
Avg Loss:  tensor(503.5853, grad_fn=<AddBackward0>)
---------

Epoch:  16
Avg Loss:  tensor(707.5839, grad_fn=<AddBackward0>)
---------

Epoch:  17
Avg Loss:  tensor(421.2487, grad_fn=<AddBackward0>)
---------

Epoch:  18
Avg Loss:  tensor(491.0224, grad_fn=<AddBackward0>)
---------

Epoch:  19
Avg Loss:  tensor(492.9494, grad_fn=<AddBackward0>)
---------

Epoch:  20
Avg Loss:  tensor(600.5839, grad_fn=<AddBackward0>)
---------

Epoch:  21
Avg Loss:  tensor(401.1357, grad_fn=<AddBackward0>)
---------

Epoch:  22
Avg Loss:  tensor(349.3068, grad_fn=<AddBackward0>)
---------

Epoch:  23
Avg Loss:  tensor(420.0032, grad_fn=<AddBackward0>)
---------

Epoch:  24
Avg Loss:  tensor(594.2241, grad_fn=<AddBackward0>)
---------

Epoch:  25
Avg Loss:  tensor(418.1927, grad_fn=<AddBackward0>)
---------

Epoch:  26
Avg Loss:  tensor(431.8441, grad_fn=<AddBackward0>)
---------

Epoch:  27
Avg Loss:  tensor(404.3432, grad_fn=<AddBackward0>)
---------

Epoch:  28
Avg Loss:  tensor(498.4893, grad_fn=<AddBackward0>)
---------

Epoch:  29
Avg Loss:  tensor(410.6434, grad_fn=<AddBackward0>)
---------

Epoch:  30
Avg Loss:  tensor(368.4830, grad_fn=<AddBackward0>)
---------

Epoch:  31
Avg Loss:  tensor(398.5204, grad_fn=<AddBackward0>)
---------

Epoch:  32
Avg Loss:  tensor(418.8934, grad_fn=<AddBackward0>)
---------

Epoch:  33
Avg Loss:  tensor(346.3491, grad_fn=<AddBackward0>)
---------

Epoch:  34
Avg Loss:  tensor(594.8478, grad_fn=<AddBackward0>)
---------

Epoch:  35
Avg Loss:  tensor(766.6990, grad_fn=<AddBackward0>)
---------

Epoch:  36
Avg Loss:  tensor(470.0198, grad_fn=<AddBackward0>)
---------

Epoch:  37
Avg Loss:  tensor(455.2559, grad_fn=<AddBackward0>)
---------

Epoch:  38
Avg Loss:  tensor(348.3211, grad_fn=<AddBackward0>)
---------

Epoch:  39
Avg Loss:  tensor(458.8055, grad_fn=<AddBackward0>)
---------

Epoch:  40
Avg Loss:  tensor(498.4775, grad_fn=<AddBackward0>)
---------

Epoch:  41
Avg Loss:  tensor(516.5922, grad_fn=<AddBackward0>)
---------

Epoch:  42
Avg Loss:  tensor(380.8783, grad_fn=<AddBackward0>)
---------

Epoch:  43
Avg Loss:  tensor(338.7972, grad_fn=<AddBackward0>)
---------

Epoch:  44
Avg Loss:  tensor(380.9538, grad_fn=<AddBackward0>)
---------

Epoch:  45
Avg Loss:  tensor(699.4338, grad_fn=<AddBackward0>)
---------

Epoch:  46
Avg Loss:  tensor(357.4874, grad_fn=<AddBackward0>)
---------

Epoch:  47
Avg Loss:  tensor(330.3051, grad_fn=<AddBackward0>)
---------

Epoch:  48
Avg Loss:  tensor(345.3000, grad_fn=<AddBackward0>)
---------

Epoch:  49
Avg Loss:  tensor(367.0319, grad_fn=<AddBackward0>)
---------

Epoch:  50
Avg Loss:  tensor(401.9725, grad_fn=<AddBackward0>)
---------

Epoch:  51
Avg Loss:  tensor(437.6883, grad_fn=<AddBackward0>)
---------

Epoch:  52
Avg Loss:  tensor(348.1149, grad_fn=<AddBackward0>)
---------

Epoch:  53
Avg Loss:  tensor(676.7428, grad_fn=<AddBackward0>)
---------

Epoch:  54
Avg Loss:  tensor(369.2166, grad_fn=<AddBackward0>)
---------

Epoch:  55
Avg Loss:  tensor(313.2010, grad_fn=<AddBackward0>)
---------

Epoch:  56
Avg Loss:  tensor(309.3873, grad_fn=<AddBackward0>)
---------

Epoch:  57
Avg Loss:  tensor(434.7744, grad_fn=<AddBackward0>)
---------

Epoch:  58
Avg Loss:  tensor(346.3869, grad_fn=<AddBackward0>)
---------

Epoch:  59
Avg Loss:  tensor(728.2587, grad_fn=<AddBackward0>)
---------

Epoch:  60
Avg Loss:  tensor(518.9315, grad_fn=<AddBackward0>)
---------

Epoch:  61
Avg Loss:  tensor(398.0027, grad_fn=<AddBackward0>)
---------

Epoch:  62
Avg Loss:  tensor(339.0151, grad_fn=<AddBackward0>)
---------

Epoch:  63
Avg Loss:  tensor(337.1242, grad_fn=<AddBackward0>)
---------

Epoch:  64
Avg Loss:  tensor(328.3404, grad_fn=<AddBackward0>)
---------

Epoch:  65
Avg Loss:  tensor(533.7964, grad_fn=<AddBackward0>)
---------

Epoch:  66
Avg Loss:  tensor(343.6622, grad_fn=<AddBackward0>)
---------

Epoch:  67
Avg Loss:  tensor(298.3811, grad_fn=<AddBackward0>)
---------

Epoch:  68
Avg Loss:  tensor(370.9352, grad_fn=<AddBackward0>)
---------

Epoch:  69
Avg Loss:  tensor(363.3209, grad_fn=<AddBackward0>)
---------

Epoch:  70
Avg Loss:  tensor(316.8472, grad_fn=<AddBackward0>)
---------

Epoch:  71
Avg Loss:  tensor(415.1136, grad_fn=<AddBackward0>)
---------

Epoch:  72
Avg Loss:  tensor(329.0317, grad_fn=<AddBackward0>)
---------

Epoch:  73
Avg Loss:  tensor(344.5092, grad_fn=<AddBackward0>)
---------

Epoch:  74
Avg Loss:  tensor(391.6874, grad_fn=<AddBackward0>)
---------

Epoch:  75
Avg Loss:  tensor(410.6600, grad_fn=<AddBackward0>)
---------

Epoch:  76
Avg Loss:  tensor(501.4120, grad_fn=<AddBackward0>)
---------

Epoch:  77
Avg Loss:  tensor(332.7773, grad_fn=<AddBackward0>)
---------

Epoch:  78
Avg Loss:  tensor(349.8069, grad_fn=<AddBackward0>)
---------

Epoch:  79
Avg Loss:  tensor(297.6289, grad_fn=<AddBackward0>)
---------

Epoch:  80
Avg Loss:  tensor(334.8741, grad_fn=<AddBackward0>)
---------

Epoch:  81
Avg Loss:  tensor(288.6993, grad_fn=<AddBackward0>)
---------

Epoch:  82
Avg Loss:  tensor(328.6041, grad_fn=<AddBackward0>)
---------

Epoch:  83
Avg Loss:  tensor(352.3408, grad_fn=<AddBackward0>)
---------

Epoch:  84
Avg Loss:  tensor(357.1957, grad_fn=<AddBackward0>)
---------

Epoch:  85
Avg Loss:  tensor(424.7294, grad_fn=<AddBackward0>)
---------

Epoch:  86
Avg Loss:  tensor(306.2493, grad_fn=<AddBackward0>)
---------

Epoch:  87
Avg Loss:  tensor(317.1253, grad_fn=<AddBackward0>)
---------

Epoch:  88
Avg Loss:  tensor(687.5830, grad_fn=<AddBackward0>)
---------

Epoch:  89
Avg Loss:  tensor(756.1082, grad_fn=<AddBackward0>)
---------

Epoch:  90
Avg Loss:  tensor(427.4254, grad_fn=<AddBackward0>)
---------

Epoch:  91
Avg Loss:  tensor(362.6285, grad_fn=<AddBackward0>)
---------

Epoch:  92
Avg Loss:  tensor(367.4178, grad_fn=<AddBackward0>)
---------

Epoch:  93
Avg Loss:  tensor(353.0275, grad_fn=<AddBackward0>)
---------

Epoch:  94
Avg Loss:  tensor(297.9775, grad_fn=<AddBackward0>)
---------

Epoch:  95
Avg Loss:  tensor(286.8870, grad_fn=<AddBackward0>)
---------

Epoch:  96
Avg Loss:  tensor(323.7460, grad_fn=<AddBackward0>)
---------

Epoch:  97
Avg Loss:  tensor(391.5286, grad_fn=<AddBackward0>)
---------

Epoch:  98
Avg Loss:  tensor(282.9677, grad_fn=<AddBackward0>)
---------

Epoch:  318
Avg Loss:  tensor(142.4686, grad_fn=<AddBackward0>)
---------

Epoch:  319
Avg Loss:  tensor(143.2707, grad_fn=<AddBackward0>)
---------

Epoch:  320
Avg Loss:  tensor(142.6750, grad_fn=<AddBackward0>)
---------

Epoch:  321
Avg Loss:  tensor(142.6906, grad_fn=<AddBackward0>)
---------

Epoch:  322
Avg Loss:  tensor(144.0155, grad_fn=<AddBackward0>)
---------

Epoch:  323
Avg Loss:  tensor(143.7548, grad_fn=<AddBackward0>)
---------

Epoch:  324
Avg Loss:  tensor(143.4299, grad_fn=<AddBackward0>)
---------

Epoch:  325
Avg Loss:  tensor(141.9505, grad_fn=<AddBackward0>)
---------

Epoch:  326
Avg Loss:  tensor(143.2532, grad_fn=<AddBackward0>)
---------

Epoch:  327
Avg Loss:  tensor(142.9404, grad_fn=<AddBackward0>)
---------

Epoch:  328
Avg Loss:  tensor(143.8545, grad_fn=<AddBackward0>)
---------

Epoch:  329
Avg Loss:  tensor(142.7649, grad_fn=<AddBackward0>)
---------

Epoch:  330
Avg Loss:  tensor(144.2528, grad_fn=<AddBackward0>)
---------

Epoch:  331
Avg Loss:  tensor(143.1456, grad_fn=<AddBackward0>)
---------

Epoch:  332
Avg Loss:  tensor(143.2429, grad_fn=<AddBackward0>)
---------

Epoch:  333
Avg Loss:  tensor(141.8145, grad_fn=<AddBackward0>)
---------

Epoch:  334
Avg Loss:  tensor(141.8893, grad_fn=<AddBackward0>)
---------

Epoch:  335
Avg Loss:  tensor(141.6477, grad_fn=<AddBackward0>)
---------

Epoch:  336
Avg Loss:  tensor(141.1084, grad_fn=<AddBackward0>)
---------

Epoch:  337
Avg Loss:  tensor(143.2547, grad_fn=<AddBackward0>)
---------

Epoch:  338
Avg Loss:  tensor(142.5614, grad_fn=<AddBackward0>)
---------

Epoch:  339
Avg Loss:  tensor(142.9999, grad_fn=<AddBackward0>)
---------

Epoch:  340
Avg Loss:  tensor(142.4731, grad_fn=<AddBackward0>)
---------

Epoch:  341
Avg Loss:  tensor(141.3938, grad_fn=<AddBackward0>)
---------

Epoch:  342
Avg Loss:  tensor(142.4990, grad_fn=<AddBackward0>)
---------

Epoch:  343
Avg Loss:  tensor(141.4008, grad_fn=<AddBackward0>)
---------

Epoch:  344
Avg Loss:  tensor(143.2209, grad_fn=<AddBackward0>)
---------

Epoch:  345
Avg Loss:  tensor(141.9611, grad_fn=<AddBackward0>)
---------

Epoch:  346
Avg Loss:  tensor(142.0788, grad_fn=<AddBackward0>)
---------

Epoch:  347
Avg Loss:  tensor(140.4494, grad_fn=<AddBackward0>)
---------

Epoch:  348
Avg Loss:  tensor(142.8334, grad_fn=<AddBackward0>)
---------

Epoch:  349
Avg Loss:  tensor(142.1779, grad_fn=<AddBackward0>)
---------

Epoch:  350
Avg Loss:  tensor(142.8158, grad_fn=<AddBackward0>)
---------

Epoch:  351
Avg Loss:  tensor(141.7473, grad_fn=<AddBackward0>)
---------

Epoch:  352
Avg Loss:  tensor(142.9294, grad_fn=<AddBackward0>)
---------

Epoch:  353
Avg Loss:  tensor(141.0574, grad_fn=<AddBackward0>)
---------

Epoch:  354
Avg Loss:  tensor(142.1839, grad_fn=<AddBackward0>)
---------

Epoch:  355
Avg Loss:  tensor(142.1815, grad_fn=<AddBackward0>)
---------

Epoch:  356
Avg Loss:  tensor(141.4149, grad_fn=<AddBackward0>)
---------

Epoch:  357
Avg Loss:  tensor(143.2263, grad_fn=<AddBackward0>)
---------

Epoch:  358
Avg Loss:  tensor(141.4533, grad_fn=<AddBackward0>)
---------

Epoch:  359
Avg Loss:  tensor(142.9512, grad_fn=<AddBackward0>)
---------

Epoch:  360
Avg Loss:  tensor(141.4034, grad_fn=<AddBackward0>)
---------

Epoch:  361
Avg Loss:  tensor(142.5682, grad_fn=<AddBackward0>)
---------

Epoch:  362
Avg Loss:  tensor(140.8239, grad_fn=<AddBackward0>)
---------

Epoch:  363
Avg Loss:  tensor(139.5599, grad_fn=<AddBackward0>)
---------

Epoch:  364
Avg Loss:  tensor(142.9250, grad_fn=<AddBackward0>)
---------

Epoch:  365
Avg Loss:  tensor(141.4426, grad_fn=<AddBackward0>)
---------

Epoch:  366
Avg Loss:  tensor(141.6549, grad_fn=<AddBackward0>)
---------

Epoch:  367
Avg Loss:  tensor(140.9675, grad_fn=<AddBackward0>)
---------

Epoch:  368
Avg Loss:  tensor(141.5517, grad_fn=<AddBackward0>)
---------

Epoch:  369
Avg Loss:  tensor(139.6099, grad_fn=<AddBackward0>)
---------

Epoch:  370
Avg Loss:  tensor(141.5424, grad_fn=<AddBackward0>)
---------

Epoch:  371
Avg Loss:  tensor(142.1242, grad_fn=<AddBackward0>)
---------

Epoch:  372
Avg Loss:  tensor(140.4537, grad_fn=<AddBackward0>)
---------

Epoch:  373
Avg Loss:  tensor(140.8910, grad_fn=<AddBackward0>)
---------

Epoch:  374
Avg Loss:  tensor(142.2631, grad_fn=<AddBackward0>)
---------

Epoch:  375
Avg Loss:  tensor(142.0005, grad_fn=<AddBackward0>)
---------

Epoch:  376
Avg Loss:  tensor(141.3448, grad_fn=<AddBackward0>)
---------

Epoch:  377
Avg Loss:  tensor(140.1943, grad_fn=<AddBackward0>)
---------

Epoch:  378
Avg Loss:  tensor(140.2164, grad_fn=<AddBackward0>)
---------

Epoch:  379
Avg Loss:  tensor(142.6857, grad_fn=<AddBackward0>)
---------

Epoch:  380
Avg Loss:  tensor(140.4619, grad_fn=<AddBackward0>)
---------

Epoch:  381
Avg Loss:  tensor(141.1201, grad_fn=<AddBackward0>)
---------

Epoch:  382
Avg Loss:  tensor(141.0113, grad_fn=<AddBackward0>)
---------

Epoch:  383
Avg Loss:  tensor(140.5986, grad_fn=<AddBackward0>)
---------

Epoch:  384
Avg Loss:  tensor(142.2439, grad_fn=<AddBackward0>)
---------

Epoch:  385
Avg Loss:  tensor(140.2984, grad_fn=<AddBackward0>)
---------

Epoch:  386
Avg Loss:  tensor(140.3753, grad_fn=<AddBackward0>)
---------

Epoch:  387
Avg Loss:  tensor(139.4847, grad_fn=<AddBackward0>)
---------

Epoch:  388
Avg Loss:  tensor(142.0026, grad_fn=<AddBackward0>)
---------

Epoch:  389
Avg Loss:  tensor(141.8528, grad_fn=<AddBackward0>)
---------

Epoch:  390
Avg Loss:  tensor(139.9360, grad_fn=<AddBackward0>)
---------

Epoch:  391
Avg Loss:  tensor(140.6420, grad_fn=<AddBackward0>)
---------

Epoch:  392
Avg Loss:  tensor(141.9057, grad_fn=<AddBackward0>)
---------

Epoch:  393
Avg Loss:  tensor(140.0320, grad_fn=<AddBackward0>)
---------

Epoch:  394
Avg Loss:  tensor(140.2020, grad_fn=<AddBackward0>)
---------

Epoch:  395
Avg Loss:  tensor(141.5951, grad_fn=<AddBackward0>)
---------

Epoch:  396
Avg Loss:  tensor(140.1652, grad_fn=<AddBackward0>)
---------

Epoch:  397
Avg Loss:  tensor(141.1411, grad_fn=<AddBackward0>)
---------

Epoch:  398
Avg Loss:  tensor(141.1074, grad_fn=<AddBackward0>)
---------

Epoch:  399
Avg Loss:  tensor(141.7729, grad_fn=<AddBackward0>)
---------

Epoch:  400
Avg Loss:  tensor(140.0776, grad_fn=<AddBackward0>)
---------

Epoch:  401
Avg Loss:  tensor(139.7817, grad_fn=<AddBackward0>)
---------

Epoch:  402
Avg Loss:  tensor(140.3950, grad_fn=<AddBackward0>)
---------

Epoch:  403
Avg Loss:  tensor(138.9477, grad_fn=<AddBackward0>)
---------

Epoch:  404
Avg Loss:  tensor(142.4452, grad_fn=<AddBackward0>)
---------

Epoch:  405
Avg Loss:  tensor(139.6112, grad_fn=<AddBackward0>)
---------

Epoch:  406
Avg Loss:  tensor(140.4602, grad_fn=<AddBackward0>)
---------

Epoch:  407
Avg Loss:  tensor(140.1919, grad_fn=<AddBackward0>)
---------

Epoch:  408
Avg Loss:  tensor(138.5648, grad_fn=<AddBackward0>)
---------

Epoch:  409
Avg Loss:  tensor(141.6114, grad_fn=<AddBackward0>)
---------

Epoch:  410
Avg Loss:  tensor(140.3426, grad_fn=<AddBackward0>)
---------

Epoch:  411
Avg Loss:  tensor(141.6451, grad_fn=<AddBackward0>)
---------

Epoch:  412
Avg Loss:  tensor(141.2879, grad_fn=<AddBackward0>)
---------

Epoch:  413
Avg Loss:  tensor(139.5673, grad_fn=<AddBackward0>)
---------

Epoch:  414
Avg Loss:  tensor(141.6735, grad_fn=<AddBackward0>)
---------

Epoch:  415
Avg Loss:  tensor(139.6027, grad_fn=<AddBackward0>)
---------

Epoch:  416
Avg Loss:  tensor(141.9543, grad_fn=<AddBackward0>)
---------

Epoch:  417
Avg Loss:  tensor(139.2069, grad_fn=<AddBackward0>)
---------

Epoch:  418
Avg Loss:  tensor(141.1133, grad_fn=<AddBackward0>)
---------

Epoch:  419
Avg Loss:  tensor(141.1118, grad_fn=<AddBackward0>)
---------

Epoch:  420
Avg Loss:  tensor(139.4973, grad_fn=<AddBackward0>)
---------

Epoch:  421
Avg Loss:  tensor(140.0224, grad_fn=<AddBackward0>)
---------

Epoch:  422
Avg Loss:  tensor(139.7448, grad_fn=<AddBackward0>)
---------

Epoch:  423
Avg Loss:  tensor(140.0255, grad_fn=<AddBackward0>)
---------

Epoch:  424
Avg Loss:  tensor(140.7331, grad_fn=<AddBackward0>)
---------

Epoch:  425
Avg Loss:  tensor(140.3563, grad_fn=<AddBackward0>)
---------

Epoch:  426
Avg Loss:  tensor(137.6523, grad_fn=<AddBackward0>)
---------

Epoch: /data/anaconda3/envs/madhu/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
 427
Avg Loss:  tensor(140.6143, grad_fn=<AddBackward0>)
---------

Epoch:  428
Avg Loss:  tensor(139.8980, grad_fn=<AddBackward0>)
---------

Epoch:  429
Avg Loss:  tensor(140.1806, grad_fn=<AddBackward0>)
---------

Epoch:  430
Avg Loss:  tensor(140.6263, grad_fn=<AddBackward0>)
---------

Epoch:  431
Avg Loss:  tensor(139.8278, grad_fn=<AddBackward0>)
---------

Epoch:  432
Avg Loss:  tensor(140.0104, grad_fn=<AddBackward0>)
---------

Epoch:  433
Avg Loss:  tensor(139.3167, grad_fn=<AddBackward0>)
---------

Epoch:  434
Avg Loss:  tensor(139.7585, grad_fn=<AddBackward0>)
---------

Epoch:  435
Avg Loss:  tensor(140.5297, grad_fn=<AddBackward0>)
---------

Epoch:  436
Avg Loss:  tensor(139.7728, grad_fn=<AddBackward0>)
---------

Epoch:  437
Avg Loss:  tensor(140.4731, grad_fn=<AddBackward0>)
---------

Epoch:  438
Avg Loss:  tensor(140.5417, grad_fn=<AddBackward0>)
---------

Epoch:  439
Avg Loss:  tensor(139.7321, grad_fn=<AddBackward0>)
---------

Epoch:  440
Avg Loss:  tensor(139.9481, grad_fn=<AddBackward0>)
---------

Epoch:  441
Avg Loss:  tensor(139.3408, grad_fn=<AddBackward0>)
---------

Epoch:  442
Avg Loss:  tensor(140.3373, grad_fn=<AddBackward0>)
---------

Epoch:  443
Avg Loss:  tensor(140.5555, grad_fn=<AddBackward0>)
---------

Epoch:  444
Avg Loss:  tensor(140.5928, grad_fn=<AddBackward0>)
---------

Epoch:  445
Avg Loss:  tensor(139.2489, grad_fn=<AddBackward0>)
---------

Epoch:  446
Avg Loss:  tensor(138.3852, grad_fn=<AddBackward0>)
---------

Epoch:  447
Avg Loss:  tensor(140.2415, grad_fn=<AddBackward0>)
---------

Epoch:  448
Avg Loss:  tensor(138.0042, grad_fn=<AddBackward0>)
---------

Epoch:  449
Avg Loss:  tensor(139.2854, grad_fn=<AddBackward0>)
---------

Epoch:  450
Avg Loss:  tensor(138.1605, grad_fn=<AddBackward0>)
---------

Epoch:  451
Avg Loss:  tensor(140.0349, grad_fn=<AddBackward0>)
---------

Epoch:  452
Avg Loss:  tensor(139.5373, grad_fn=<AddBackward0>)
---------

Epoch:  453
Avg Loss:  tensor(140.4635, grad_fn=<AddBackward0>)
---------

Epoch:  454
Avg Loss:  tensor(138.9704, grad_fn=<AddBackward0>)
---------

Epoch:  455
Avg Loss:  tensor(140.4056, grad_fn=<AddBackward0>)
---------

Epoch:  456
Avg Loss:  tensor(139.3271, grad_fn=<AddBackward0>)
---------

Epoch:  457
Avg Loss:  tensor(139.6662, grad_fn=<AddBackward0>)
---------

Epoch:  458
Avg Loss:  tensor(140.4844, grad_fn=<AddBackward0>)
---------

Epoch:  459
Avg Loss:  tensor(140.4748, grad_fn=<AddBackward0>)
---------

Epoch:  460
Avg Loss:  tensor(139.1663, grad_fn=<AddBackward0>)
---------

Epoch:  461
Avg Loss:  tensor(138.6393, grad_fn=<AddBackward0>)
---------

Epoch:  462
Avg Loss:  tensor(138.0904, grad_fn=<AddBackward0>)
---------

Epoch:  463
Avg Loss:  tensor(140.9896, grad_fn=<AddBackward0>)
---------

Epoch:  464
Avg Loss:  tensor(139.7672, grad_fn=<AddBackward0>)
---------

Epoch:  465
Avg Loss:  tensor(137.4908, grad_fn=<AddBackward0>)
---------

Epoch:  466
Avg Loss:  tensor(139.6515, grad_fn=<AddBackward0>)
---------

Epoch:  467
Avg Loss:  tensor(139.2566, grad_fn=<AddBackward0>)
---------

Epoch:  468
Avg Loss:  tensor(139.2223, grad_fn=<AddBackward0>)
---------

Epoch:  469
Avg Loss:  tensor(139.7675, grad_fn=<AddBackward0>)
---------

Epoch:  470
Avg Loss:  tensor(138.6023, grad_fn=<AddBackward0>)
---------

Epoch:  471
Avg Loss:  tensor(139.8294, grad_fn=<AddBackward0>)
---------

Epoch:  472
Avg Loss:  tensor(139.3494, grad_fn=<AddBackward0>)
---------

Epoch:  473
Avg Loss:  tensor(137.9658, grad_fn=<AddBackward0>)
---------

Epoch:  474
Avg Loss:  tensor(139.0962, grad_fn=<AddBackward0>)
---------

Epoch:  475
Avg Loss:  tensor(140.3286, grad_fn=<AddBackward0>)
---------

Epoch:  476
Avg Loss:  tensor(139.0819, grad_fn=<AddBackward0>)
---------

Epoch:  477
Avg Loss:  tensor(138.5618, grad_fn=<AddBackward0>)
---------

Epoch:  478
Avg Loss:  tensor(137.5708, grad_fn=<AddBackward0>)
---------

Epoch:  479
Avg Loss:  tensor(138.5694, grad_fn=<AddBackward0>)
---------

Epoch:  480
Avg Loss:  tensor(139.3088, grad_fn=<AddBackward0>)
---------

Epoch:  481
Avg Loss:  tensor(140.5238, grad_fn=<AddBackward0>)
---------

Epoch:  482
Avg Loss:  tensor(139.5179, grad_fn=<AddBackward0>)
---------

Epoch:  483
Avg Loss:  tensor(139.4844, grad_fn=<AddBackward0>)
---------

Epoch:  484
Avg Loss:  tensor(138.5117, grad_fn=<AddBackward0>)
---------

Epoch:  485
Avg Loss:  tensor(138.6298, grad_fn=<AddBackward0>)
---------

Epoch:  486
Avg Loss:  tensor(139.0829, grad_fn=<AddBackward0>)
---------

Epoch:  487
Avg Loss:  tensor(139.5439, grad_fn=<AddBackward0>)
---------

Epoch:  488
Avg Loss:  tensor(138.7901, grad_fn=<AddBackward0>)
---------

Epoch:  489
Avg Loss:  tensor(139.5243, grad_fn=<AddBackward0>)
---------

Epoch:  490
Avg Loss:  tensor(139.3378, grad_fn=<AddBackward0>)
---------

Epoch:  491
Avg Loss:  tensor(139.1061, grad_fn=<AddBackward0>)
---------

Epoch:  492
Avg Loss:  tensor(140.4421, grad_fn=<AddBackward0>)
---------

Epoch:  493
Avg Loss:  tensor(138.1607, grad_fn=<AddBackward0>)
---------

Epoch:  494
Avg Loss:  tensor(139.8421, grad_fn=<AddBackward0>)
---------

Epoch:  495
Avg Loss:  tensor(137.4012, grad_fn=<AddBackward0>)
---------

Epoch:  496
Avg Loss:  tensor(138.7422, grad_fn=<AddBackward0>)
---------

Epoch:  497
Avg Loss:  tensor(140.1129, grad_fn=<AddBackward0>)
---------

Epoch:  498
Avg Loss:  tensor(138.3399, grad_fn=<AddBackward0>)
---------

Epoch:  499
Avg Loss:  tensor(137.9136, grad_fn=<AddBackward0>)
---------


---------

Epoch:  99
Avg Loss:  tensor(323.3351, grad_fn=<AddBackward0>)
---------

Epoch:  100
Avg Loss:  tensor(349.6539, grad_fn=<AddBackward0>)
---------

Epoch:  101
Avg Loss:  tensor(357.8793, grad_fn=<AddBackward0>)
---------

Epoch:  102
Avg Loss:  tensor(310.4826, grad_fn=<AddBackward0>)
---------

Epoch:  103
Avg Loss:  tensor(384.2736, grad_fn=<AddBackward0>)
---------

Epoch:  104
Avg Loss:  tensor(359.0698, grad_fn=<AddBackward0>)
---------

Epoch:  105
Avg Loss:  tensor(304.3259, grad_fn=<AddBackward0>)
---------

Epoch:  106
Avg Loss:  tensor(277.4590, grad_fn=<AddBackward0>)
---------

Epoch:  107
Avg Loss:  tensor(295.2361, grad_fn=<AddBackward0>)
---------

Epoch:  108
Avg Loss:  tensor(346.4753, grad_fn=<AddBackward0>)
---------

Epoch:  109
Avg Loss:  tensor(303.7437, grad_fn=<AddBackward0>)
---------

Epoch:  110
Avg Loss:  tensor(270.9978, grad_fn=<AddBackward0>)
---------

Epoch:  111
Avg Loss:  tensor(285.0232, grad_fn=<AddBackward0>)
---------

Epoch:  112
Avg Loss:  tensor(376.4739, grad_fn=<AddBackward0>)
---------

Epoch:  113
Avg Loss:  tensor(299.9463, grad_fn=<AddBackward0>)
---------

Epoch:  114
Avg Loss:  tensor(251.9829, grad_fn=<AddBackward0>)
---------

Epoch:  115
Avg Loss:  tensor(316.2103, grad_fn=<AddBackward0>)
---------

Epoch:  116
Avg Loss:  tensor(284.5180, grad_fn=<AddBackward0>)
---------

Epoch:  117
Avg Loss:  tensor(467.6515, grad_fn=<AddBackward0>)
---------

Epoch:  118
Avg Loss:  tensor(277.9672, grad_fn=<AddBackward0>)
---------

Epoch:  119
Avg Loss:  tensor(280.1911, grad_fn=<AddBackward0>)
---------

Epoch:  120
Avg Loss:  tensor(321.5097, grad_fn=<AddBackward0>)
---------

Epoch:  121
Avg Loss:  tensor(304.4402, grad_fn=<AddBackward0>)
---------

Epoch:  122
Avg Loss:  tensor(360.6850, grad_fn=<AddBackward0>)
---------

Epoch:  123
Avg Loss:  tensor(300.2578, grad_fn=<AddBackward0>)
---------

Epoch:  124
Avg Loss:  tensor(264.1984, grad_fn=<AddBackward0>)
---------

Epoch:  125
Avg Loss:  tensor(336.9031, grad_fn=<AddBackward0>)
---------

Epoch:  126
Avg Loss:  tensor(289.7291, grad_fn=<AddBackward0>)
---------

Epoch:  127
Avg Loss:  tensor(269.4957, grad_fn=<AddBackward0>)
---------

Epoch:  128
Avg Loss:  tensor(311.6229, grad_fn=<AddBackward0>)
---------

Epoch:  129
Avg Loss:  tensor(299.2008, grad_fn=<AddBackward0>)
---------

Epoch:  130
Avg Loss:  tensor(271.0980, grad_fn=<AddBackward0>)
---------

Epoch:  131
Avg Loss:  tensor(279.0318, grad_fn=<AddBackward0>)
---------

Epoch:  132
Avg Loss:  tensor(322.2011, grad_fn=<AddBackward0>)
---------

Epoch:  133
Avg Loss:  tensor(281.8224, grad_fn=<AddBackward0>)
---------

Epoch:  134
Avg Loss:  tensor(305.8002, grad_fn=<AddBackward0>)
---------

Epoch:  135
Avg Loss:  tensor(301.9315, grad_fn=<AddBackward0>)
---------

Epoch:  136
Avg Loss:  tensor(344.6815, grad_fn=<AddBackward0>)
---------

Epoch:  137
Avg Loss:  tensor(497.4456, grad_fn=<AddBackward0>)
---------

Epoch:  138
Avg Loss:  tensor(297.2737, grad_fn=<AddBackward0>)
---------

Epoch:  139
Avg Loss:  tensor(296.9366, grad_fn=<AddBackward0>)
---------

Epoch:  140
Avg Loss:  tensor(284.2037, grad_fn=<AddBackward0>)
---------

Epoch:  141
Avg Loss:  tensor(269.2168, grad_fn=<AddBackward0>)
---------

Epoch:  142
Avg Loss:  tensor(436.6492, grad_fn=<AddBackward0>)
---------

Epoch:  143
Avg Loss:  tensor(358.2437, grad_fn=<AddBackward0>)
---------

Epoch:  144
Avg Loss:  tensor(294.5972, grad_fn=<AddBackward0>)
---------

Epoch:  145
Avg Loss:  tensor(293.8923, grad_fn=<AddBackward0>)
---------

Epoch:  146
Avg Loss:  tensor(260.7202, grad_fn=<AddBackward0>)
---------

Epoch:  147
Avg Loss:  tensor(353.6764, grad_fn=<AddBackward0>)
---------

Epoch:  148
Avg Loss:  tensor(283.7296, grad_fn=<AddBackward0>)
---------

Epoch:  149
Avg Loss:  tensor(296.2045, grad_fn=<AddBackward0>)
---------

Epoch:  150
Avg Loss:  tensor(281.6429, grad_fn=<AddBackward0>)
---------

Epoch:  151
Avg Loss:  tensor(250.4349, grad_fn=<AddBackward0>)
---------

Epoch:  152
Avg Loss:  tensor(287.5127, grad_fn=<AddBackward0>)
---------

Epoch:  153
Avg Loss:  tensor(284.6255, grad_fn=<AddBackward0>)
---------

Epoch:  154
Avg Loss:  tensor(286.8664, grad_fn=<AddBackward0>)
---------

Epoch:  155
Avg Loss:  tensor(263.3074, grad_fn=<AddBackward0>)
---------

Epoch:  156
Avg Loss:  tensor(270.5605, grad_fn=<AddBackward0>)
---------

Epoch:  157
Avg Loss:  tensor(289.3966, grad_fn=<AddBackward0>)
---------

Epoch:  158
Avg Loss:  tensor(257.3589, grad_fn=<AddBackward0>)
---------

Epoch:  159
Avg Loss:  tensor(268.2453, grad_fn=<AddBackward0>)
---------

Epoch:  160
Avg Loss:  tensor(275.3236, grad_fn=<AddBackward0>)
---------

Epoch:  161
Avg Loss:  tensor(258.8265, grad_fn=<AddBackward0>)
---------

Epoch:  162
Avg Loss:  tensor(281.6175, grad_fn=<AddBackward0>)
---------

Epoch:  163
Avg Loss:  tensor(339.9035, grad_fn=<AddBackward0>)
---------

Epoch:  164
Avg Loss:  tensor(289.7309, grad_fn=<AddBackward0>)
---------

Epoch:  165
Avg Loss:  tensor(268.1282, grad_fn=<AddBackward0>)
---------

Epoch:  166
Avg Loss:  tensor(453.1171, grad_fn=<AddBackward0>)
---------

Epoch:  167
Avg Loss:  tensor(357.0983, grad_fn=<AddBackward0>)
---------

Epoch:  168
Avg Loss:  tensor(309.5173, grad_fn=<AddBackward0>)
---------

Epoch:  169
Avg Loss:  tensor(337.0789, grad_fn=<AddBackward0>)
---------

Epoch:  170
Avg Loss:  tensor(262.8104, grad_fn=<AddBackward0>)
---------

Epoch:  171
Avg Loss:  tensor(255.1142, grad_fn=<AddBackward0>)
---------

Epoch:  172
Avg Loss:  tensor(251.5218, grad_fn=<AddBackward0>)
---------

Epoch:  173
Avg Loss:  tensor(269.9709, grad_fn=<AddBackward0>)
---------

Epoch:  174
Avg Loss:  tensor(296.0941, grad_fn=<AddBackward0>)
---------

Epoch:  175
Avg Loss:  tensor(261.5910, grad_fn=<AddBackward0>)
---------

Epoch:  176
Avg Loss:  tensor(302.4044, grad_fn=<AddBackward0>)
---------

Epoch:  177
Avg Loss:  tensor(243.1938, grad_fn=<AddBackward0>)
---------

Epoch:  178
Avg Loss:  tensor(239.6338, grad_fn=<AddBackward0>)
---------

Epoch:  179
Avg Loss:  tensor(271.1657, grad_fn=<AddBackward0>)
---------

Epoch:  180
Avg Loss:  tensor(303.4053, grad_fn=<AddBackward0>)
---------

Epoch:  181
Avg Loss:  tensor(357.9609, grad_fn=<AddBackward0>)
---------

Epoch:  182
Avg Loss:  tensor(283.4641, grad_fn=<AddBackward0>)
---------

Epoch:  183
Avg Loss:  tensor(281.3270, grad_fn=<AddBackward0>)
---------

Epoch:  184
Avg Loss:  tensor(276.3354, grad_fn=<AddBackward0>)
---------

Epoch:  185
Avg Loss:  tensor(273.7227, grad_fn=<AddBackward0>)
---------

Epoch:  186
Avg Loss:  tensor(271.9913, grad_fn=<AddBackward0>)
---------

Epoch:  187
Avg Loss:  tensor(269.0688, grad_fn=<AddBackward0>)
---------

Epoch:  188
Avg Loss:  tensor(271.5195, grad_fn=<AddBackward0>)
---------

Epoch:  189
Avg Loss:  tensor(252.5150, grad_fn=<AddBackward0>)
---------

Epoch:  190
Avg Loss:  tensor(276.2425, grad_fn=<AddBackward0>)
---------

Epoch:  191
Avg Loss:  tensor(241.8235, grad_fn=<AddBackward0>)
---------

Epoch:  192
Avg Loss:  tensor(230.0996, grad_fn=<AddBackward0>)
---------

Epoch:  193
Avg Loss:  tensor(260.5760, grad_fn=<AddBackward0>)
---------

Epoch:  194
Avg Loss:  tensor(247.0259, grad_fn=<AddBackward0>)
---------

Epoch:  195
Avg Loss:  tensor(450.4888, grad_fn=<AddBackward0>)
---------

Epoch:  196
Avg Loss:  tensor(408.6586, grad_fn=<AddBackward0>)
---------

Epoch:  197
Avg Loss:  tensor(285.7630, grad_fn=<AddBackward0>)
---------

Epoch:  198
Avg Loss:  tensor(275.2066, grad_fn=<AddBackward0>)
---------

Epoch:  199
Avg Loss:  tensor(260.8051, grad_fn=<AddBackward0>)
---------

Epoch:  200
Avg Loss:  tensor(276.8268, grad_fn=<AddBackward0>)
---------

Epoch:  201
Avg Loss:  tensor(278.9039, grad_fn=<AddBackward0>)
---------

Epoch:  202
Avg Loss:  tensor(233.3731, grad_fn=<AddBackward0>)
---------

Epoch:  203
Avg Loss:  tensor(264.1365, grad_fn=<AddBackward0>)
---------

Epoch:  204
Avg Loss:  tensor(320.2879, grad_fn=<AddBackward0>)
---------

Epoch:  205
Avg Loss:  tensor(281.0999, grad_fn=<AddBackward0>)
---------

Epoch:  206
Avg Loss:  tensor(345.8434, grad_fn=<AddBackward0>)
---------

Epoch:  207
Avg Loss:  tensor(298.9939, grad_fn=<AddBackward0>)
---------

Epoch:  208
Avg Loss:  tensor(247.5698, grad_fn=<AddBackward0>)
---------

Epoch:  209
Avg Loss:  tensor(232.8417, grad_fn=<AddBackward0>)
---------

Epoch:  210
Avg Loss:  tensor(241.3004, grad_fn=<AddBackward0>)
---------

Epoch:  211
Avg Loss:  tensor(279.9687, grad_fn=<AddBackward0>)
---------

Epoch:  212
Avg Loss:  tensor(256.6337, grad_fn=<AddBackward0>)
---------

Epoch:  213
Avg Loss:  tensor(253.4093, grad_fn=<AddBackward0>)
---------

Epoch:  214
Avg Loss:  tensor(250.2946, grad_fn=<AddBackward0>)
---------

Epoch:  215
Avg Loss:  tensor(240.6812, grad_fn=<AddBackward0>)
---------

Epoch:  216
Avg Loss:  tensor(255.5090, grad_fn=<AddBackward0>)
---------

Epoch:  217
Avg Loss:  tensor(259.0016, grad_fn=<AddBackward0>)
---------

Epoch:  218
Avg Loss:  tensor(263.3586, grad_fn=<AddBackward0>)
---------

Epoch:  219
Avg Loss:  tensor(283.9934, grad_fn=<AddBackward0>)
---------

Epoch:  220
Avg Loss:  tensor(254.8969, grad_fn=<AddBackward0>)
---------

Epoch:  221
Avg Loss:  tensor(254.6554, grad_fn=<AddBackward0>)
---------

Epoch:  222
Avg Loss:  tensor(251.7879, grad_fn=<AddBackward0>)
---------

Epoch:  223
Avg Loss:  tensor(242.2463, grad_fn=<AddBackward0>)
---------

Epoch:  224
Avg Loss:  tensor(286.6146, grad_fn=<AddBackward0>)
---------

Epoch:  225
Avg Loss:  tensor(394.2948, grad_fn=<AddBackward0>)
---------

Epoch:  226
Avg Loss:  tensor(274.2061, grad_fn=<AddBackward0>)
---------

Epoch:  227
Avg Loss:  tensor(264.0052, grad_fn=<AddBackward0>)
---------

Epoch:  228
Avg Loss:  tensor(234.1693, grad_fn=<AddBackward0>)
---------

Epoch:  229
Avg Loss:  tensor(281.7049, grad_fn=<AddBackward0>)
---------

Epoch:  230
Avg Loss:  tensor(257.5365, grad_fn=<AddBackward0>)
---------

Epoch:  231
Avg Loss:  tensor(249.4827, grad_fn=<AddBackward0>)
---------

Epoch:  232
Avg Loss:  tensor(289.8362, grad_fn=<AddBackward0>)
---------

Epoch:  233
Avg Loss:  tensor(292.5855, grad_fn=<AddBackward0>)
---------

Epoch:  234
Avg Loss:  tensor(297.0939, grad_fn=<AddBackward0>)
---------

Epoch:  235
Avg Loss:  tensor(236.4841, grad_fn=<AddBackward0>)
---------

Epoch:  236
Avg Loss:  tensor(274.6746, grad_fn=<AddBackward0>)
---------

Epoch:  237
Avg Loss:  tensor(267.8126, grad_fn=<AddBackward0>)
---------

Epoch:  238
Avg Loss:  tensor(257.7342, grad_fn=<AddBackward0>)
---------

Epoch:  239
Avg Loss:  tensor(250.5239, grad_fn=<AddBackward0>)
---------

Epoch:  240
Avg Loss:  tensor(269.7513, grad_fn=<AddBackward0>)
---------

Epoch:  241
Avg Loss:  tensor(275.3336, grad_fn=<AddBackward0>)
---------

Epoch:  242
Avg Loss:  tensor(234.1472, grad_fn=<AddBackward0>)
---------

Epoch:  243
Avg Loss:  tensor(267.1592, grad_fn=<AddBackward0>)
---------

Epoch:  244
Avg Loss:  tensor(262.2705, grad_fn=<AddBackward0>)
---------

Epoch:  245
Avg Loss:  tensor(272.5179, grad_fn=<AddBackward0>)
---------

Epoch:  246
Avg Loss:  tensor(247.1947, grad_fn=<AddBackward0>)
---------

Epoch:  247
Avg Loss:  tensor(229.3728, grad_fn=<AddBackward0>)
---------

Epoch:  248
Avg Loss:  tensor(265.8532, grad_fn=<AddBackward0>)
---------

Epoch:  249
Avg Loss:  tensor(258.6807, grad_fn=<AddBackward0>)
---------

Epoch:  250
Avg Loss:  tensor(260.2567, grad_fn=<AddBackward0>)
---------

Epoch:  251
Avg Loss:  tensor(238.0872, grad_fn=<AddBackward0>)
---------

Epoch:  252
Avg Loss:  tensor(227.2944, grad_fn=<AddBackward0>)
---------

Epoch:  253
Avg Loss:  tensor(223.7349, grad_fn=<AddBackward0>)
---------

Epoch:  254
Avg Loss:  tensor(242.7091, grad_fn=<AddBackward0>)
---------

Epoch:  255
Avg Loss:  tensor(240.5411, grad_fn=<AddBackward0>)
---------

Epoch:  256
Avg Loss:  tensor(277.7272, grad_fn=<AddBackward0>)
---------

Epoch:  257
Avg Loss:  tensor(245.1428, grad_fn=<AddBackward0>)
---------

Epoch:  258
Avg Loss:  tensor(222.5230, grad_fn=<AddBackward0>)
---------

Epoch:  259
Avg Loss:  tensor(215.0699, grad_fn=<AddBackward0>)
---------

Epoch:  260
Avg Loss:  tensor(387.3665, grad_fn=<AddBackward0>)
---------

Epoch:  261
Avg Loss:  tensor(234.3551, grad_fn=<AddBackward0>)
---------

Epoch:  262
Avg Loss:  tensor(242.9958, grad_fn=<AddBackward0>)
---------

Epoch:  263
Avg Loss:  tensor(238.6638, grad_fn=<AddBackward0>)
---------

Epoch:  264
Avg Loss:  tensor(255.2379, grad_fn=<AddBackward0>)
---------

Epoch:  265
Avg Loss:  tensor(321.3520, grad_fn=<AddBackward0>)
---------

Epoch:  266
Avg Loss:  tensor(272.7269, grad_fn=<AddBackward0>)
---------

Epoch:  267
Avg Loss:  tensor(247.0289, grad_fn=<AddBackward0>)
---------

Epoch:  268
Avg Loss:  tensor(241.4774, grad_fn=<AddBackward0>)
---------

Epoch:  269
Avg Loss:  tensor(242.5089, grad_fn=<AddBackward0>)
---------

Epoch:  270
Avg Loss:  tensor(241.6132, grad_fn=<AddBackward0>)
---------

Epoch:  271
Avg Loss:  tensor(249.7729, grad_fn=<AddBackward0>)
---------

Epoch:  272
Avg Loss:  tensor(249.4357, grad_fn=<AddBackward0>)
---------

Epoch:  273
Avg Loss:  tensor(228.1599, grad_fn=<AddBackward0>)
---------

Epoch:  274
Avg Loss:  tensor(253.8859, grad_fn=<AddBackward0>)
---------

Epoch:  275
Avg Loss:  tensor(243.2356, grad_fn=<AddBackward0>)
---------

Epoch:  276
Avg Loss:  tensor(239.2207, grad_fn=<AddBackward0>)
---------

Epoch:  277
Avg Loss:  tensor(229.9211, grad_fn=<AddBackward0>)
---------

Epoch:  278
Avg Loss:  tensor(254.0868, grad_fn=<AddBackward0>)
---------

Epoch:  279
Avg Loss:  tensor(253.2165, grad_fn=<AddBackward0>)
---------

Epoch:  280
Avg Loss:  tensor(246.4958, grad_fn=<AddBackward0>)
---------

Epoch:  281
Avg Loss:  tensor(261.4242, grad_fn=<AddBackward0>)
---------

Epoch:  282
Avg Loss:  tensor(249.8699, grad_fn=<AddBackward0>)
---------

Epoch:  283
Avg Loss:  tensor(240.3875, grad_fn=<AddBackward0>)
---------

Epoch:  284
Avg Loss:  tensor(248.5051, grad_fn=<AddBackward0>)
---------

Epoch:  285
Avg Loss:  tensor(263.8682, grad_fn=<AddBackward0>)
---------

Epoch:  286
Avg Loss:  tensor(247.2735, grad_fn=<AddBackward0>)
---------

Epoch:  287
Avg Loss:  tensor(222.1973, grad_fn=<AddBackward0>)
---------

Epoch:  288
Avg Loss:  tensor(229.8721, grad_fn=<AddBackward0>)
---------

Epoch:  289
Avg Loss:  tensor(243.2263, grad_fn=<AddBackward0>)
---------

Epoch:  290
Avg Loss:  tensor(245.5253, grad_fn=<AddBackward0>)
---------

Epoch:  291
Avg Loss:  tensor(227.2014, grad_fn=<AddBackward0>)
---------

Epoch:  292
Avg Loss:  tensor(286.1179, grad_fn=<AddBackward0>)
---------

Epoch:  293
Avg Loss:  tensor(247.6794, grad_fn=<AddBackward0>)
---------

Epoch:  294
Avg Loss:  tensor(215.0563, grad_fn=<AddBackward0>)
---------

Epoch:  295
Avg Loss:  tensor(235.5807, grad_fn=<AddBackward0>)
---------

Epoch:  296
Avg Loss:  tensor(245.0881, grad_fn=<AddBackward0>)
---------

Epoch:  297
Avg Loss:  tensor(246.2968, grad_fn=<AddBackward0>)
---------

Epoch:  298
Avg Loss:  tensor(230.7767, grad_fn=<AddBackward0>)
---------

Epoch:  299
Avg Loss:  tensor(236.1940, grad_fn=<AddBackward0>)
---------

Epoch:  300
Avg Loss:  tensor(256.2056, grad_fn=<AddBackward0>)
---------

Epoch:  301
Avg Loss:  tensor(248.9849, grad_fn=<AddBackward0>)
---------

Epoch:  302
Avg Loss:  tensor(246.0381, grad_fn=<AddBackward0>)
---------

Epoch:  303
Avg Loss:  tensor(233.7328, grad_fn=<AddBackward0>)
---------

Epoch:  304
Avg Loss:  tensor(229.6828, grad_fn=<AddBackward0>)
---------

Epoch:  305
Avg Loss:  tensor(232.6987, grad_fn=<AddBackward0>)
---------

Epoch:  306
Avg Loss:  tensor(231.7408, grad_fn=<AddBackward0>)
---------

Epoch:  307
Avg Loss:  tensor(214.3002, grad_fn=<AddBackward0>)
---------

Epoch:  308
Avg Loss:  tensor(230.0608, grad_fn=<AddBackward0>)
---------

Epoch:  309
Avg Loss:  tensor(227.5117, grad_fn=<AddBackward0>)
---------

Epoch:  310
Avg Loss:  tensor(225.0368, grad_fn=<AddBackward0>)
---------

Epoch:  311
Avg Loss:  tensor(233.7141, grad_fn=<AddBackward0>)
---------

Epoch:  312
Avg Loss:  tensor(228.7279, grad_fn=<AddBackward0>)
---------

Epoch:  313
Avg Loss:  tensor(224.8657, grad_fn=<AddBackward0>)
---------

Epoch:  314
Avg Loss:  tensor(245.5830, grad_fn=<AddBackward0>)
---------

Epoch:  315
Avg Loss:  tensor(231.6183, grad_fn=<AddBackward0>)
---------

Epoch:  316
Avg Loss:  tensor(249.9081, grad_fn=<AddBackward0>)
---------

Epoch:  317
Avg Loss:  tensor(222.2059, grad_fn=<AddBackward0>)
---------

Epoch:  318
Avg Loss:  tensor(249.8158, grad_fn=<AddBackward0>)
---------

Epoch:  319
Avg Loss:  tensor(215.0004, grad_fn=<AddBackward0>)
---------

Epoch:  320
Avg Loss:  tensor(292.1035, grad_fn=<AddBackward0>)
---------

Epoch:  321
Avg Loss:  tensor(299.4081, grad_fn=<AddBackward0>)
---------

Epoch:  322
Avg Loss:  tensor(239.0892, grad_fn=<AddBackward0>)
---------

Epoch:  323
Avg Loss:  tensor(236.1687, grad_fn=<AddBackward0>)
---------

Epoch:  324
Avg Loss:  tensor(214.2339, grad_fn=<AddBackward0>)
---------

Epoch:  325
Avg Loss:  tensor(242.5989, grad_fn=<AddBackward0>)
---------

Epoch:  326
Avg Loss:  tensor(232.5151, grad_fn=<AddBackward0>)
---------

Epoch:  327
Avg Loss:  tensor(221.5087, grad_fn=<AddBackward0>)
---------

Epoch:  328
Avg Loss:  tensor(241.1105, grad_fn=<AddBackward0>)
---------

Epoch:  329
Avg Loss:  tensor(239.0809, grad_fn=<AddBackward0>)
---------

Epoch:  330
Avg Loss:  tensor(245.3333, grad_fn=<AddBackward0>)
---------

Epoch:  331
Avg Loss:  tensor(231.2335, grad_fn=<AddBackward0>)
---------

Epoch:  332
Avg Loss:  tensor(241.7927, grad_fn=<AddBackward0>)
---------

Epoch:  333
Avg Loss:  tensor(229.1970, grad_fn=<AddBackward0>)
---------

Epoch:  334
Avg Loss:  tensor(235.4501, grad_fn=<AddBackward0>)
---------

Epoch:  335
Avg Loss:  tensor(234.0214, grad_fn=<AddBackward0>)
---------

Epoch:  336
Avg Loss:  tensor(258.5933, grad_fn=<AddBackward0>)
---------

Epoch:  337
Avg Loss:  tensor(222.0240, grad_fn=<AddBackward0>)
---------

Epoch:  338
Avg Loss:  tensor(228.8220, grad_fn=<AddBackward0>)
---------

Epoch:  339
Avg Loss:  tensor(243.7429, grad_fn=<AddBackward0>)
---------

Epoch:  340
Avg Loss:  tensor(257.9093, grad_fn=<AddBackward0>)
---------

Epoch:  341
Avg Loss:  tensor(244.6657, grad_fn=<AddBackward0>)
---------

Epoch:  342
Avg Loss:  tensor(236.8469, grad_fn=<AddBackward0>)
---------

Epoch:  343
Avg Loss:  tensor(222.1794, grad_fn=<AddBackward0>)
---------

Epoch:  344
Avg Loss:  tensor(221.2581, grad_fn=<AddBackward0>)
---------

Epoch:  345
Avg Loss:  tensor(241.2494, grad_fn=<AddBackward0>)
---------

Epoch:  346
Avg Loss:  tensor(263.9930, grad_fn=<AddBackward0>)
---------

Epoch:  347
Avg Loss:  tensor(230.9365, grad_fn=<AddBackward0>)
---------

Epoch:  348
Avg Loss:  tensor(229.8097, grad_fn=<AddBackward0>)
---------

Epoch:  349
Avg Loss:  tensor(244.0312, grad_fn=<AddBackward0>)
---------

Epoch:  350
Avg Loss:  tensor(233.7077, grad_fn=<AddBackward0>)
---------

Epoch:  351
Avg Loss:  tensor(229.2004, grad_fn=<AddBackward0>)
---------

Epoch:  352
Avg Loss:  tensor(235.0681, grad_fn=<AddBackward0>)
---------

Epoch:  353
Avg Loss:  tensor(229.1719, grad_fn=<AddBackward0>)
---------

Epoch:  354
Avg Loss:  tensor(210.3760, grad_fn=<AddBackward0>)
---------

Epoch:  355
Avg Loss:  tensor(234.8619, grad_fn=<AddBackward0>)
---------

Epoch:  356
Avg Loss:  tensor(211.0579, grad_fn=<AddBackward0>)
---------

Epoch:  357
Avg Loss:  tensor(213.3268, grad_fn=<AddBackward0>)
---------

Epoch:  358
Avg Loss:  tensor(313.3362, grad_fn=<AddBackward0>)
---------

Epoch:  359
Avg Loss:  tensor(336.9660, grad_fn=<AddBackward0>)
---------

Epoch:  360
Avg Loss:  tensor(288.0325, grad_fn=<AddBackward0>)
---------

Epoch:  361
Avg Loss:  tensor(242.9991, grad_fn=<AddBackward0>)
---------

Epoch:  362
Avg Loss:  tensor(238.3637, grad_fn=<AddBackward0>)
---------

Epoch:  363
Avg Loss:  tensor(210.8699, grad_fn=<AddBackward0>)
---------

Epoch:  364
Avg Loss:  tensor(219.3856, grad_fn=<AddBackward0>)
---------

Epoch:  365
Avg Loss:  tensor(244.6276, grad_fn=<AddBackward0>)
---------

Epoch:  366
Avg Loss:  tensor(228.5734, grad_fn=<AddBackward0>)
---------

Epoch:  367
Avg Loss:  tensor(221.8455, grad_fn=<AddBackward0>)
---------

Epoch:  368
Avg Loss:  tensor(211.8219, grad_fn=<AddBackward0>)
---------

Epoch:  369
Avg Loss:  tensor(212.2890, grad_fn=<AddBackward0>)
---------

Epoch:  370
Avg Loss:  tensor(238.4874, grad_fn=<AddBackward0>)
---------

Epoch:  371
Avg Loss:  tensor(231.6606, grad_fn=<AddBackward0>)
---------

Epoch:  372
Avg Loss:  tensor(276.5591, grad_fn=<AddBackward0>)
---------

Epoch:  373
Avg Loss:  tensor(225.3105, grad_fn=<AddBackward0>)
---------

Epoch:  374
Avg Loss:  tensor(226.6730, grad_fn=<AddBackward0>)
---------

Epoch:  375
Avg Loss:  tensor(246.9387, grad_fn=<AddBackward0>)
---------

Epoch:  376
Avg Loss:  tensor(237.3466, grad_fn=<AddBackward0>)
---------

Epoch:  377
Avg Loss:  tensor(221.8642, grad_fn=<AddBackward0>)
---------

Epoch:  378
Avg Loss:  tensor(213.6038, grad_fn=<AddBackward0>)
---------

Epoch:  379
Avg Loss:  tensor(249.4012, grad_fn=<AddBackward0>)
---------

Epoch:  380
Avg Loss:  tensor(209.9754, grad_fn=<AddBackward0>)
---------

Epoch:  381
Avg Loss:  tensor(218.6984, grad_fn=<AddBackward0>)
---------

Epoch:  382
Avg Loss:  tensor(220.0377, grad_fn=<AddBackward0>)
---------

Epoch:  383
Avg Loss:  tensor(279.5793, grad_fn=<AddBackward0>)
---------

Epoch:  384
Avg Loss:  tensor(234.9252, grad_fn=<AddBackward0>)
---------

Epoch:  385
Avg Loss:  tensor(226.6556, grad_fn=<AddBackward0>)
---------

Epoch:  386
Avg Loss:  tensor(216.3585, grad_fn=<AddBackward0>)
---------

Epoch:  387
Avg Loss:  tensor(235.5834, grad_fn=<AddBackward0>)
---------

Epoch:  388
Avg Loss:  tensor(207.6860, grad_fn=<AddBackward0>)
---------

Epoch:  389
Avg Loss:  tensor(219.0090, grad_fn=<AddBackward0>)
---------

Epoch:  390
Avg Loss:  tensor(236.2361, grad_fn=<AddBackward0>)
---------

Epoch:  391
Avg Loss:  tensor(236.1442, grad_fn=<AddBackward0>)
---------

Epoch:  392
Avg Loss:  tensor(239.1003, grad_fn=<AddBackward0>)
---------

Epoch:  393
Avg Loss:  tensor(198.6410, grad_fn=<AddBackward0>)
---------

Epoch:  394
Avg Loss:  tensor(240.1369, grad_fn=<AddBackward0>)
---------

Epoch:  395
Avg Loss:  tensor(225.3627, grad_fn=<AddBackward0>)
---------

Epoch:  396
Avg Loss:  tensor(216.2238, grad_fn=<AddBackward0>)
---------

Epoch:  397
Avg Loss:  tensor(225.9215, grad_fn=<AddBackward0>)
---------

Epoch:  398
Avg Loss:  tensor(227.3708, grad_fn=<AddBackward0>)
---------

Epoch:  399
Avg Loss:  tensor(211.3642, grad_fn=<AddBackward0>)
---------

Epoch:  400
Avg Loss:  tensor(205.8413, grad_fn=<AddBackward0>)
---------

Epoch:  401
Avg Loss:  tensor(262.1938, grad_fn=<AddBackward0>)
---------

Epoch:  402
Avg Loss:  tensor(217.3344, grad_fn=<AddBackward0>)
---------

Epoch:  403
Avg Loss:  tensor(214.6550, grad_fn=<AddBackward0>)
---------

Epoch:  404
Avg Loss:  tensor(208.2179, grad_fn=<AddBackward0>)
---------

Epoch:  405
Avg Loss:  tensor(231.9529, grad_fn=<AddBackward0>)
---------

Epoch:  406
Avg Loss:  tensor(213.1060, grad_fn=<AddBackward0>)
---------

Epoch:  407
Avg Loss:  tensor(234.2054, grad_fn=<AddBackward0>)
---------

Epoch:  408
Avg Loss:  tensor(219.3141, grad_fn=<AddBackward0>)
---------

Epoch:  409
Avg Loss:  tensor(227.9279, grad_fn=<AddBackward0>)
---------

Epoch:  410
Avg Loss:  tensor(213.6417, grad_fn=<AddBackward0>)
---------

Epoch:  411
Avg Loss:  tensor(229.9182, grad_fn=<AddBackward0>)
---------

Epoch:  412
Avg Loss:  tensor(235.7004, grad_fn=<AddBackward0>)
---------

Epoch:  413
Avg Loss:  tensor(207.9664, grad_fn=<AddBackward0>)
---------

Epoch:  414
Avg Loss:  tensor(214.3925, grad_fn=<AddBackward0>)
---------

Epoch:  415
Avg Loss:  tensor(205.9919, grad_fn=<AddBackward0>)
---------

Epoch:  416
Avg Loss:  tensor(226.9617, grad_fn=<AddBackward0>)
---------

Epoch:  417
Avg Loss:  tensor(240.3691, grad_fn=<AddBackward0>)
---------

Epoch:  418
Avg Loss:  tensor(239.1829, grad_fn=<AddBackward0>)
---------

Epoch:  419
Avg Loss:  tensor(198.9581, grad_fn=<AddBackward0>)
---------

Epoch:  420
Avg Loss:  tensor(219.0495, grad_fn=<AddBackward0>)
---------

Epoch:  421
Avg Loss:  tensor(231.6505, grad_fn=<AddBackward0>)
---------

Epoch:  422
Avg Loss:  tensor(235.0394, grad_fn=<AddBackward0>)
---------

Epoch:  423
Avg Loss:  tensor(213.0668, grad_fn=<AddBackward0>)
---------

Epoch:  424
Avg Loss:  tensor(255.1346, grad_fn=<AddBackward0>)
---------

Epoch:  425
Avg Loss:  tensor(238.8169, grad_fn=<AddBackward0>)
---------

Epoch:  426
Avg Loss:  tensor(229.1165, grad_fn=<AddBackward0>)
---------

Epoch: /data/anaconda3/envs/madhu/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
 427
Avg Loss:  tensor(218.6852, grad_fn=<AddBackward0>)
---------

Epoch:  428
Avg Loss:  tensor(222.5276, grad_fn=<AddBackward0>)
---------

Epoch:  429
Avg Loss:  tensor(223.3448, grad_fn=<AddBackward0>)
---------

Epoch:  430
Avg Loss:  tensor(208.7484, grad_fn=<AddBackward0>)
---------

Epoch:  431
Avg Loss:  tensor(215.0629, grad_fn=<AddBackward0>)
---------

Epoch:  432
Avg Loss:  tensor(201.6909, grad_fn=<AddBackward0>)
---------

Epoch:  433
Avg Loss:  tensor(213.9444, grad_fn=<AddBackward0>)
---------

Epoch:  434
Avg Loss:  tensor(228.1881, grad_fn=<AddBackward0>)
---------

Epoch:  435
Avg Loss:  tensor(216.2464, grad_fn=<AddBackward0>)
---------

Epoch:  436
Avg Loss:  tensor(224.2566, grad_fn=<AddBackward0>)
---------

Epoch:  437
Avg Loss:  tensor(211.9658, grad_fn=<AddBackward0>)
---------

Epoch:  438
Avg Loss:  tensor(208.9564, grad_fn=<AddBackward0>)
---------

Epoch:  439
Avg Loss:  tensor(233.1112, grad_fn=<AddBackward0>)
---------

Epoch:  440
Avg Loss:  tensor(246.9748, grad_fn=<AddBackward0>)
---------

Epoch:  441
Avg Loss:  tensor(314.6258, grad_fn=<AddBackward0>)
---------

Epoch:  442
Avg Loss:  tensor(248.9783, grad_fn=<AddBackward0>)
---------

Epoch:  443
Avg Loss:  tensor(239.4406, grad_fn=<AddBackward0>)
---------

Epoch:  444
Avg Loss:  tensor(211.0479, grad_fn=<AddBackward0>)
---------

Epoch:  445
Avg Loss:  tensor(215.4489, grad_fn=<AddBackward0>)
---------

Epoch:  446
Avg Loss:  tensor(226.0824, grad_fn=<AddBackward0>)
---------

Epoch:  447
Avg Loss:  tensor(216.8325, grad_fn=<AddBackward0>)
---------

Epoch:  448
Avg Loss:  tensor(229.4409, grad_fn=<AddBackward0>)
---------

Epoch:  449
Avg Loss:  tensor(204.7097, grad_fn=<AddBackward0>)
---------

Epoch:  450
Avg Loss:  tensor(209.4923, grad_fn=<AddBackward0>)
---------

Epoch:  451
Avg Loss:  tensor(205.5569, grad_fn=<AddBackward0>)
---------

Epoch:  452
Avg Loss:  tensor(205.3283, grad_fn=<AddBackward0>)
---------

Epoch:  453
Avg Loss:  tensor(216.9588, grad_fn=<AddBackward0>)
---------

Epoch:  454
Avg Loss:  tensor(215.3458, grad_fn=<AddBackward0>)
---------

Epoch:  455
Avg Loss:  tensor(208.3986, grad_fn=<AddBackward0>)
---------

Epoch:  456
Avg Loss:  tensor(196.6546, grad_fn=<AddBackward0>)
---------

Epoch:  457
Avg Loss:  tensor(238.9911, grad_fn=<AddBackward0>)
---------

Epoch:  458
Avg Loss:  tensor(235.7054, grad_fn=<AddBackward0>)
---------

Epoch:  459
Avg Loss:  tensor(218.6573, grad_fn=<AddBackward0>)
---------

Epoch:  460
Avg Loss:  tensor(222.6509, grad_fn=<AddBackward0>)
---------

Epoch:  461
Avg Loss:  tensor(220.4836, grad_fn=<AddBackward0>)
---------

Epoch:  462
Avg Loss:  tensor(209.7786, grad_fn=<AddBackward0>)
---------

Epoch:  463
Avg Loss:  tensor(226.2484, grad_fn=<AddBackward0>)
---------

Epoch:  464
Avg Loss:  tensor(208.1372, grad_fn=<AddBackward0>)
---------

Epoch:  465
Avg Loss:  tensor(234.3652, grad_fn=<AddBackward0>)
---------

Epoch:  466
Avg Loss:  tensor(233.5351, grad_fn=<AddBackward0>)
---------

Epoch:  467
Avg Loss:  tensor(209.4660, grad_fn=<AddBackward0>)
---------

Epoch:  468
Avg Loss:  tensor(217.1068, grad_fn=<AddBackward0>)
---------

Epoch:  469
Avg Loss:  tensor(208.4347, grad_fn=<AddBackward0>)
---------

Epoch:  470
Avg Loss:  tensor(203.0248, grad_fn=<AddBackward0>)
---------

Epoch:  471
Avg Loss:  tensor(211.0481, grad_fn=<AddBackward0>)
---------

Epoch:  472
Avg Loss:  tensor(205.5083, grad_fn=<AddBackward0>)
---------

Epoch:  473
Avg Loss:  tensor(215.5782, grad_fn=<AddBackward0>)
---------

Epoch:  474
Avg Loss:  tensor(201.6837, grad_fn=<AddBackward0>)
---------

Epoch:  475
Avg Loss:  tensor(200.2426, grad_fn=<AddBackward0>)
---------

Epoch:  476
Avg Loss:  tensor(190.4089, grad_fn=<AddBackward0>)
---------

Epoch:  477
Avg Loss:  tensor(204.2481, grad_fn=<AddBackward0>)
---------

Epoch:  478
Avg Loss:  tensor(192.8077, grad_fn=<AddBackward0>)
---------

Epoch:  479
Avg Loss:  tensor(395.2224, grad_fn=<AddBackward0>)
---------

Epoch:  480
Avg Loss:  tensor(260.7744, grad_fn=<AddBackward0>)
---------

Epoch:  481
Avg Loss:  tensor(249.1419, grad_fn=<AddBackward0>)
---------

Epoch:  482
Avg Loss:  tensor(213.5888, grad_fn=<AddBackward0>)
---------

Epoch:  483
Avg Loss:  tensor(204.9842, grad_fn=<AddBackward0>)
---------

Epoch:  484
Avg Loss:  tensor(213.1817, grad_fn=<AddBackward0>)
---------

Epoch:  485
Avg Loss:  tensor(213.1885, grad_fn=<AddBackward0>)
---------

Epoch:  486
Avg Loss:  tensor(201.5162, grad_fn=<AddBackward0>)
---------

Epoch:  487
Avg Loss:  tensor(197.2524, grad_fn=<AddBackward0>)
---------

Epoch:  488
Avg Loss:  tensor(215.9042, grad_fn=<AddBackward0>)
---------

Epoch:  489
Avg Loss:  tensor(207.8593, grad_fn=<AddBackward0>)
---------

Epoch:  490
Avg Loss:  tensor(235.1897, grad_fn=<AddBackward0>)
---------

Epoch:  491
Avg Loss:  tensor(198.9953, grad_fn=<AddBackward0>)
---------

Epoch:  492
Avg Loss:  tensor(201.6898, grad_fn=<AddBackward0>)
---------

Epoch:  493
Avg Loss:  tensor(196.7907, grad_fn=<AddBackward0>)
---------

Epoch:  494
Avg Loss:  tensor(203.0155, grad_fn=<AddBackward0>)
---------

Epoch:  495
Avg Loss:  tensor(223.0647, grad_fn=<AddBackward0>)
---------

Epoch:  496
Avg Loss:  tensor(207.8262, grad_fn=<AddBackward0>)
---------

Epoch:  497
Avg Loss:  tensor(221.6223, grad_fn=<AddBackward0>)
---------

Epoch:  498
Avg Loss:  tensor(197.9123, grad_fn=<AddBackward0>)
---------

Epoch:  499
Avg Loss:  tensor(213.5250, grad_fn=<AddBackward0>)
---------

